{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation System\n",
    "Collaborative filtering with implicit feedback based on latent factors. Prepare data on user-item relationships for each user-company in format that ALS can use.\n",
    "We require each unique assignee ID in the rows of the matrix, and each unique item ID in columns of matrix.\n",
    "Values of matrix should be (?) binary user-item preference * confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from test_model import (get_patent_fields_list, get_ml_patents, \n",
    "                        create_title_abstract_col,trim_data, \n",
    "                        structure_dataframe, partition_dataframe, \n",
    "                        build_pipeline, process_docs, pat_inv_map, get_topics)\n",
    "\n",
    "from rec_system import alphanum_to_int, int_to_alphanum\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary, mmcorpus\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import AuthorTopicModel\n",
    "from gensim.test.utils import common_dictionary, datapath, temporary_file\n",
    "from smart_open import smart_open\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, punkt, RegexpTokenizer, wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import calendar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.137.2.208:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a2041eb70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.137.2.208:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data understanding - Acquire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data understanding - Acquire data for text workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickled dataset\n",
    "with open('/Users/lee/Documents/techniche/techniche/data/raw_data_1000', 'rb') as f:\n",
    "    raw_data_1000 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keys as criteria to subset dataset #1 for non-text workflows\n",
    "retained_keys = ['patent_number', 'patent_firstnamed_assignee_id']\n",
    "\n",
    "# subset raw dataset by desired keys/columns\n",
    "data_1000 = trim_data(data=raw_data_1000, keys=retained_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keys as criteria to subset dataset #2, for text workflows\n",
    "retained_keys_2 = ['patent_number', 'patent_firstnamed_assignee_id',\n",
    "                   'patent_title', 'patent_abstract']\n",
    "\n",
    "# subset raw dataset by desired keys/columns for text analysis workflows\n",
    "data_1000_2 = trim_data(data=raw_data_1000, keys=retained_keys_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new item in dataset #2 by concat of patent_title and patent_abstract\n",
    "data_1000_2 = create_title_abstract_col(data=data_1000_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Pandas dataframe from dataset #1\n",
    "df_1000 = pd.DataFrame(data_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tools and techniques for the rapid, continuous...</td>\n",
       "      <td>org_VU2IXnxgxGIK8A8oQrwm</td>\n",
       "      <td>10226194</td>\n",
       "      <td>Statistical, noninvasive measurement of a pati...</td>\n",
       "      <td>Statistical, noninvasive measurement of a pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The disclosure relates to structural health mo...</td>\n",
       "      <td>org_9cmRc2rH8nbl8O9VuxYL</td>\n",
       "      <td>10228278</td>\n",
       "      <td>Determining a health condition of a structure</td>\n",
       "      <td>Determining a health condition of a structure....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A scenario is defined that including models of...</td>\n",
       "      <td>org_8O8xQifxyiW5pZB2KuDx</td>\n",
       "      <td>10228693</td>\n",
       "      <td>Generating simulated sensor data for training ...</td>\n",
       "      <td>Generating simulated sensor data for training ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     patent_abstract  \\\n",
       "0  Tools and techniques for the rapid, continuous...   \n",
       "1  The disclosure relates to structural health mo...   \n",
       "2  A scenario is defined that including models of...   \n",
       "\n",
       "  patent_firstnamed_assignee_id patent_number  \\\n",
       "0      org_VU2IXnxgxGIK8A8oQrwm      10226194   \n",
       "1      org_9cmRc2rH8nbl8O9VuxYL      10228278   \n",
       "2      org_8O8xQifxyiW5pZB2KuDx      10228693   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Statistical, noninvasive measurement of a pati...   \n",
       "1      Determining a health condition of a structure   \n",
       "2  Generating simulated sensor data for training ...   \n",
       "\n",
       "                               patent_title_abstract  \n",
       "0  Statistical, noninvasive measurement of a pati...  \n",
       "1  Determining a health condition of a structure....  \n",
       "2  Generating simulated sensor data for training ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Pandas dataframe from dataset #2\n",
    "df_1000_2 = pd.DataFrame(data_1000_2)\n",
    "df_1000_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset #1: drop row that contains invalid data\n",
    "df_1000[df_1000.patent_number.str.contains('[RE]')]\n",
    "df_1000 = df_1000.drop(df_1000.index[[717]])\n",
    "\n",
    "# drop NaNs in patent_firstnamed_assignee_id column\n",
    "df_1000 = df_1000.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset#2: drop row that contains invalid data\n",
    "df_1000_2[df_1000_2.patent_number.str.contains('[RE]')]\n",
    "df_1000_2 = df_1000_2.drop(df_1000_2.index[[717]])\n",
    "\n",
    "# drop NaNs in patent_firstnamed_assignee_id column\n",
    "df_1000_2 = df_1000_2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation - model #1\n",
    "Prepare data on user-item relationships for each user-company in format that ALS can use.\n",
    "We require each unique assignee ID in the rows of the matrix, and each unique item ID in columns of matrix.\n",
    "Values of matrix should be (?) binary user-item preference * confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new rating column and assign value of 1\n",
    "df_1000['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert patent_number column from string to int\n",
    "df_1000 = df_1000.astype({'patent_number': 'int64'})\n",
    "# uncomment to confirm\n",
    "# df_1000.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert alphanumeric patent_firstnamed_assignee_id col to int\n",
    "df_1000 = df_1000.astype({'patent_number': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1000['patent_firstnamed_assignee_id'] = df_1000['patent_firstnamed_assignee_id'].apply(hash).apply(abs)\n",
    "df_1000['patent_firstnamed_assignee_id'] = df_1000['patent_firstnamed_assignee_id'].apply(hash).apply(abs) % 65536 # 2^16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1000['patent_firstnamed_assignee_id'] = df_1000['patent_firstnamed_assignee_id'].apply(hash).apply(abs)\n",
    "df_1000['patent_number'] = df_1000['patent_number'] % 65536 # 2^16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000 = df_1000.astype({'patent_firstnamed_assignee_id': 'int'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation - model #1 - create Spark dataframe from pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df_1000 = spark.createDataFrame(df_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast columns from bigint to int\n",
    "sp_df_1000_2 = sp_df_1000.withColumn(\"patent_firstnamed_assignee_id\",\n",
    "                                     sp_df_1000[\"patent_firstnamed_assignee_id\"]\n",
    "                                     .cast(IntegerType())).withColumn(\"patent_number\",\n",
    "                                                                      sp_df_1000[\"patent_number\"].\n",
    "                                                                      cast(IntegerType()))\n",
    "                                                          .withColumn(\"rating\", sp_df_1000[\"rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition dataframe \n",
    "(training, test) = sp_df_1000.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model # 1\n",
    "Build the recommendation model using ALS on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ALS recommendation model\n",
    "als = ALS(maxIter=5,\n",
    "          regParam=0.01, \n",
    "          rank=10, # number of latent topics- ME-10?\n",
    "          alpha=30,\n",
    "          implicitPrefs=True, # # implicitPrefs=True b/c ratings are implicit\n",
    "          userCol=\"patent_firstnamed_assignee_id\", \n",
    "          itemCol=\"patent_number\", \n",
    "          ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"nan\") # coldStartStrategy=\"nan\" to retain NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit ALS model to the training set\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #1 - Evaluation - Compare to naive baseline\n",
    "Compare model evaluation result with naive baseline model that only outputs (for explicit - the average rating (or you may try one that outputs the average rating per movie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #1 - Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test set\n",
    "predictions_test = model.transform(test)\n",
    "predictions_test_df = predictions_test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>rating</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59878</td>\n",
       "      <td>3997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25713</td>\n",
       "      <td>9900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59878</td>\n",
       "      <td>26087</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59878</td>\n",
       "      <td>32304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26407</td>\n",
       "      <td>43256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6623</td>\n",
       "      <td>54258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30640</td>\n",
       "      <td>34602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11061</td>\n",
       "      <td>2525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30542</td>\n",
       "      <td>3986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59749</td>\n",
       "      <td>4042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27923</td>\n",
       "      <td>27977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>59878</td>\n",
       "      <td>32291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36006</td>\n",
       "      <td>44792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11779</td>\n",
       "      <td>16232</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10846</td>\n",
       "      <td>21675</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2507</td>\n",
       "      <td>32489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29115</td>\n",
       "      <td>47655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41328</td>\n",
       "      <td>52071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1056</td>\n",
       "      <td>16027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30661</td>\n",
       "      <td>36499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59878</td>\n",
       "      <td>36649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38056</td>\n",
       "      <td>4396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11779</td>\n",
       "      <td>15931</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13546</td>\n",
       "      <td>22307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3421</td>\n",
       "      <td>30219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>59130</td>\n",
       "      <td>46149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6623</td>\n",
       "      <td>56148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>59878</td>\n",
       "      <td>14760</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>59878</td>\n",
       "      <td>16800</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5519</td>\n",
       "      <td>22313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>32299</td>\n",
       "      <td>3148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>46972</td>\n",
       "      <td>51861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>49243</td>\n",
       "      <td>52657</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>34128</td>\n",
       "      <td>56688</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>48311</td>\n",
       "      <td>57845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>36006</td>\n",
       "      <td>62199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>27923</td>\n",
       "      <td>14909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>11061</td>\n",
       "      <td>63567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>27408</td>\n",
       "      <td>3870</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>6351</td>\n",
       "      <td>18188</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>11779</td>\n",
       "      <td>44835</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>47302</td>\n",
       "      <td>57717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>30661</td>\n",
       "      <td>64679</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>56831</td>\n",
       "      <td>52005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>11779</td>\n",
       "      <td>788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>33377</td>\n",
       "      <td>58478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>19329</td>\n",
       "      <td>60104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>32636</td>\n",
       "      <td>617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>11779</td>\n",
       "      <td>3993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>59878</td>\n",
       "      <td>11246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>6623</td>\n",
       "      <td>22647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>23241</td>\n",
       "      <td>29018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>59878</td>\n",
       "      <td>57552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>59878</td>\n",
       "      <td>2511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>27408</td>\n",
       "      <td>27319</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>48109</td>\n",
       "      <td>30199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>3421</td>\n",
       "      <td>38299</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>11779</td>\n",
       "      <td>64569</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>59878</td>\n",
       "      <td>15913</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>59878</td>\n",
       "      <td>44387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patent_firstnamed_assignee_id  patent_number  rating  prediction\n",
       "0                            59878           3997       1    0.977067\n",
       "1                            25713           9900       1    0.363925\n",
       "2                            59878          26087       1    0.977067\n",
       "3                            59878          32304       1    0.977067\n",
       "4                            26407          43256       1    0.364367\n",
       "5                             6623          54258       1    0.878919\n",
       "6                            30640          34602       1    0.364231\n",
       "7                            11061           2525       1    0.875135\n",
       "8                            30542           3986       1    0.364142\n",
       "9                            59749           4042       1    0.364071\n",
       "10                           27923          27977       1    0.646579\n",
       "11                           59878          32291       1    0.977067\n",
       "12                           36006          44792       1    0.859978\n",
       "13                           11779          16232       1    0.936678\n",
       "14                           10846          21675       1    0.559878\n",
       "15                            2507          32489       1    0.364352\n",
       "16                           29115          47655       1    0.559782\n",
       "17                           41328          52071       1    0.364415\n",
       "18                            1056          16027       1    0.364409\n",
       "19                           30661          36499       1    0.820540\n",
       "20                           59878          36649       1    0.977067\n",
       "21                           38056           4396       1    0.821139\n",
       "22                           11779          15931       1    0.936678\n",
       "23                           13546          22307       1    0.364074\n",
       "24                            3421          30219       1    0.910120\n",
       "25                           59130          46149       1    0.364217\n",
       "26                            6623          56148       1    0.878919\n",
       "27                           59878          14760       1    0.977067\n",
       "28                           59878          16800       1    0.977067\n",
       "29                            5519          22313       1    0.559750\n",
       "..                             ...            ...     ...         ...\n",
       "727                          32299           3148       1    0.364185\n",
       "728                          46972          51861       1    0.559560\n",
       "729                          49243          52657       1    0.364222\n",
       "730                          34128          56688       1    0.364108\n",
       "731                          48311          57845       1    0.559860\n",
       "732                          36006          62199       1    0.859978\n",
       "733                          27923          14909       1    0.646579\n",
       "734                          11061          63567       1    0.875135\n",
       "735                          27408           3870       1    0.733093\n",
       "736                           6351          18188       1    0.559895\n",
       "737                          11779          44835       1    0.936678\n",
       "738                          47302          57717       1    0.559509\n",
       "739                          30661          64679       1    0.820540\n",
       "740                          56831          52005       1    0.646550\n",
       "741                          11779            788       1    0.936678\n",
       "742                          33377          58478       1    0.646434\n",
       "743                          19329          60104       1    0.364238\n",
       "744                          32636            617       1    0.364207\n",
       "745                          11779           3993       1    0.936678\n",
       "746                          59878          11246       1    0.977067\n",
       "747                           6623          22647       1    0.878919\n",
       "748                          23241          29018       1    0.646747\n",
       "749                          59878          57552       1    0.977067\n",
       "750                          59878           2511       1    0.977067\n",
       "751                          27408          27319       1    0.733093\n",
       "752                          48109          30199       1    0.364353\n",
       "753                           3421          38299       1    0.910120\n",
       "754                          11779          64569       1    0.936678\n",
       "755                          59878          15913       1    0.977067\n",
       "756                          59878          44387       1    0.977067\n",
       "\n",
       "[757 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions for training set\n",
    "predictions_train = model.transform(training)\n",
    "predictions_train_df = predictions_train.toPandas()\n",
    "predictions_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>rating</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59878</td>\n",
       "      <td>3997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25713</td>\n",
       "      <td>9900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59878</td>\n",
       "      <td>26087</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59878</td>\n",
       "      <td>32304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26407</td>\n",
       "      <td>43256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6623</td>\n",
       "      <td>54258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30640</td>\n",
       "      <td>34602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11061</td>\n",
       "      <td>2525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30542</td>\n",
       "      <td>3986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59749</td>\n",
       "      <td>4042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27923</td>\n",
       "      <td>27977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>59878</td>\n",
       "      <td>32291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36006</td>\n",
       "      <td>44792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11779</td>\n",
       "      <td>16232</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10846</td>\n",
       "      <td>21675</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2507</td>\n",
       "      <td>32489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29115</td>\n",
       "      <td>47655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41328</td>\n",
       "      <td>52071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1056</td>\n",
       "      <td>16027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30661</td>\n",
       "      <td>36499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59878</td>\n",
       "      <td>36649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38056</td>\n",
       "      <td>4396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11779</td>\n",
       "      <td>15931</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13546</td>\n",
       "      <td>22307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3421</td>\n",
       "      <td>30219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>59130</td>\n",
       "      <td>46149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6623</td>\n",
       "      <td>56148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>59878</td>\n",
       "      <td>14760</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>59878</td>\n",
       "      <td>16800</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5519</td>\n",
       "      <td>22313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>32299</td>\n",
       "      <td>3148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>46972</td>\n",
       "      <td>51861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>49243</td>\n",
       "      <td>52657</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>34128</td>\n",
       "      <td>56688</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>48311</td>\n",
       "      <td>57845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>36006</td>\n",
       "      <td>62199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>27923</td>\n",
       "      <td>14909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>11061</td>\n",
       "      <td>63567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>27408</td>\n",
       "      <td>3870</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>6351</td>\n",
       "      <td>18188</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>11779</td>\n",
       "      <td>44835</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>47302</td>\n",
       "      <td>57717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>30661</td>\n",
       "      <td>64679</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>56831</td>\n",
       "      <td>52005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>11779</td>\n",
       "      <td>788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>33377</td>\n",
       "      <td>58478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>19329</td>\n",
       "      <td>60104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>32636</td>\n",
       "      <td>617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>11779</td>\n",
       "      <td>3993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>59878</td>\n",
       "      <td>11246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>6623</td>\n",
       "      <td>22647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>23241</td>\n",
       "      <td>29018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>59878</td>\n",
       "      <td>57552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>59878</td>\n",
       "      <td>2511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>27408</td>\n",
       "      <td>27319</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>48109</td>\n",
       "      <td>30199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>3421</td>\n",
       "      <td>38299</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>11779</td>\n",
       "      <td>64569</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>59878</td>\n",
       "      <td>15913</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>59878</td>\n",
       "      <td>44387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patent_firstnamed_assignee_id  patent_number  rating  prediction\n",
       "0                            59878           3997       1    0.977067\n",
       "1                            25713           9900       1    0.363925\n",
       "2                            59878          26087       1    0.977067\n",
       "3                            59878          32304       1    0.977067\n",
       "4                            26407          43256       1    0.364367\n",
       "5                             6623          54258       1    0.878919\n",
       "6                            30640          34602       1    0.364231\n",
       "7                            11061           2525       1    0.875135\n",
       "8                            30542           3986       1    0.364142\n",
       "9                            59749           4042       1    0.364071\n",
       "10                           27923          27977       1    0.646579\n",
       "11                           59878          32291       1    0.977067\n",
       "12                           36006          44792       1    0.859978\n",
       "13                           11779          16232       1    0.936678\n",
       "14                           10846          21675       1    0.559878\n",
       "15                            2507          32489       1    0.364352\n",
       "16                           29115          47655       1    0.559782\n",
       "17                           41328          52071       1    0.364415\n",
       "18                            1056          16027       1    0.364409\n",
       "19                           30661          36499       1    0.820540\n",
       "20                           59878          36649       1    0.977067\n",
       "21                           38056           4396       1    0.821139\n",
       "22                           11779          15931       1    0.936678\n",
       "23                           13546          22307       1    0.364074\n",
       "24                            3421          30219       1    0.910120\n",
       "25                           59130          46149       1    0.364217\n",
       "26                            6623          56148       1    0.878919\n",
       "27                           59878          14760       1    0.977067\n",
       "28                           59878          16800       1    0.977067\n",
       "29                            5519          22313       1    0.559750\n",
       "..                             ...            ...     ...         ...\n",
       "727                          32299           3148       1    0.364185\n",
       "728                          46972          51861       1    0.559560\n",
       "729                          49243          52657       1    0.364222\n",
       "730                          34128          56688       1    0.364108\n",
       "731                          48311          57845       1    0.559860\n",
       "732                          36006          62199       1    0.859978\n",
       "733                          27923          14909       1    0.646579\n",
       "734                          11061          63567       1    0.875135\n",
       "735                          27408           3870       1    0.733093\n",
       "736                           6351          18188       1    0.559895\n",
       "737                          11779          44835       1    0.936678\n",
       "738                          47302          57717       1    0.559509\n",
       "739                          30661          64679       1    0.820540\n",
       "740                          56831          52005       1    0.646550\n",
       "741                          11779            788       1    0.936678\n",
       "742                          33377          58478       1    0.646434\n",
       "743                          19329          60104       1    0.364238\n",
       "744                          32636            617       1    0.364207\n",
       "745                          11779           3993       1    0.936678\n",
       "746                          59878          11246       1    0.977067\n",
       "747                           6623          22647       1    0.878919\n",
       "748                          23241          29018       1    0.646747\n",
       "749                          59878          57552       1    0.977067\n",
       "750                          59878           2511       1    0.977067\n",
       "751                          27408          27319       1    0.733093\n",
       "752                          48109          30199       1    0.364353\n",
       "753                           3421          38299       1    0.910120\n",
       "754                          11779          64569       1    0.936678\n",
       "755                          59878          15913       1    0.977067\n",
       "756                          59878          44387       1    0.977067\n",
       "\n",
       "[757 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>rating</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [patent_firstnamed_assignee_id, patent_number, rating, prediction]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text = train_test_split(df_1000_2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Data preparation - text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF vectorization of patents - metrics - avg distance between individual patents, with ranking\n",
    "- take tf-idf vector and argsort by absolute value, to see which features are most important to patent\n",
    "- get top 20 features. normally would do cosine distance betweel all vectors. BUT, only do cosine distance between these top 20 features, for cold start patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate TF-IDF Vectorizer using standard English stopwords\n",
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit TF-IDF matrix on text column\n",
    "tfidf_matrix = tfidf.fit_transform(train_text['patent_title_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777, 4924)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output matrix, 972 docs, 5364 terms\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - compute distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cosine similarity matrix between docs using linear_kernel\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct reverse map of indices and pat_title_abstract\n",
    "indices = pd.Series(train_text.index, index = train_text['patent_title_abstract']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>An electronic device can receive user input vi...</td>\n",
       "      <td>org_EilEWQcC6UiqHcSGx9mb</td>\n",
       "      <td>10192549</td>\n",
       "      <td>Extending digital personal assistant action pr...</td>\n",
       "      <td>Extending digital personal assistant action pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>A graymail detection and filtering system pred...</td>\n",
       "      <td>org_hZHBoHvjQMoGbVbMF740</td>\n",
       "      <td>9954805</td>\n",
       "      <td>Graymail filtering-based on user preferences</td>\n",
       "      <td>Graymail filtering-based on user preferences. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>A computer system automatically generates serv...</td>\n",
       "      <td>org_EilEWQcC6UiqHcSGx9mb</td>\n",
       "      <td>9954746</td>\n",
       "      <td>Automatically generating service documentation...</td>\n",
       "      <td>Automatically generating service documentation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>A system may include multiple personal data so...</td>\n",
       "      <td>org_oBgJHolxfEg0kgVOfKYg</td>\n",
       "      <td>10140322</td>\n",
       "      <td>Tools and techniques for extracting knowledge ...</td>\n",
       "      <td>Tools and techniques for extracting knowledge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>The present disclosure relates to a system and...</td>\n",
       "      <td>org_U6feekQVzPuPglpgKSBc</td>\n",
       "      <td>10175979</td>\n",
       "      <td>Defect ownership assignment system and predict...</td>\n",
       "      <td>Defect ownership assignment system and predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Methods and a system are provided that is perf...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10003923</td>\n",
       "      <td>Location context inference based on user mobil...</td>\n",
       "      <td>Location context inference based on user mobil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>A machine learning model is trained by definin...</td>\n",
       "      <td>org_8O8xQifxyiW5pZB2KuDx</td>\n",
       "      <td>10055675</td>\n",
       "      <td>Training algorithm for collision avoidance usi...</td>\n",
       "      <td>Training algorithm for collision avoidance usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>A data analysis system stores in-memory repres...</td>\n",
       "      <td>org_uSkGGmX0kIBgxQmYxLGK</td>\n",
       "      <td>10185930</td>\n",
       "      <td>Collaboration using shared documents for proce...</td>\n",
       "      <td>Collaboration using shared documents for proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>A computer-implemented method, a processing pi...</td>\n",
       "      <td>org_FMQQGwWD4see8cTUvBeX</td>\n",
       "      <td>9946924</td>\n",
       "      <td>System and method for automating information a...</td>\n",
       "      <td>System and method for automating information a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>The invention provides an autonomous vehicle c...</td>\n",
       "      <td>org_UfP75xYv5uGvK5xNfkLe</td>\n",
       "      <td>10073462</td>\n",
       "      <td>Autonomous vehicle with improved visual detect...</td>\n",
       "      <td>Autonomous vehicle with improved visual detect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>A method and system for teaching an object of ...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10170117</td>\n",
       "      <td>User-guided teaching an object of a deictic re...</td>\n",
       "      <td>User-guided teaching an object of a deictic re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Technology for link parameter identification i...</td>\n",
       "      <td>org_S4ohigZQayeHnhlzllnG</td>\n",
       "      <td>10171161</td>\n",
       "      <td>Machine learning for link parameter identifica...</td>\n",
       "      <td>Machine learning for link parameter identifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Methods, devices, systems, and non-transitory ...</td>\n",
       "      <td>org_BMNBDoKtp8BLidFVt55K</td>\n",
       "      <td>10049327</td>\n",
       "      <td>Application characterization for machine learn...</td>\n",
       "      <td>Application characterization for machine learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>A security platform employs a variety techniqu...</td>\n",
       "      <td>org_FnwHVjRQWWObkacCtbJp</td>\n",
       "      <td>10148677</td>\n",
       "      <td>Model training and deployment in complex event...</td>\n",
       "      <td>Model training and deployment in complex event...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Mined semantic analysis techniques (MSA) inclu...</td>\n",
       "      <td>org_oGjQ7OAz5h3J1vYCd4s6</td>\n",
       "      <td>9880999</td>\n",
       "      <td>Natural language relatedness tool using mined ...</td>\n",
       "      <td>Natural language relatedness tool using mined ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>First content containing a plurality of list i...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10140273</td>\n",
       "      <td>List manipulation in natural language processing</td>\n",
       "      <td>List manipulation in natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>The present disclosure is directed to extracti...</td>\n",
       "      <td>org_6LK9HJqqm2RNBebbySEF</td>\n",
       "      <td>10084725</td>\n",
       "      <td>Extracting features from a NoC for machine lea...</td>\n",
       "      <td>Extracting features from a NoC for machine lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>The disclosed solution uses machine learning-b...</td>\n",
       "      <td>org_m0hwKu6AOhMMpHWb6CrO</td>\n",
       "      <td>9910845</td>\n",
       "      <td>Call flow and discourse analysis</td>\n",
       "      <td>Call flow and discourse analysis. The disclose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>An acoustic array system for anomaly detection...</td>\n",
       "      <td>org_jgiwLxLF4g3IhRpgbvYS</td>\n",
       "      <td>9984543</td>\n",
       "      <td>Anomaly detection system and method</td>\n",
       "      <td>Anomaly detection system and method. An acoust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Systems and methods are provided for estimatin...</td>\n",
       "      <td>org_oeYwik2sRVlspT4VbRYA</td>\n",
       "      <td>10127496</td>\n",
       "      <td>System and method for estimating arrival time</td>\n",
       "      <td>System and method for estimating arrival time....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Predicting program performance on hardware dev...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10032114</td>\n",
       "      <td>Predicting application performance on hardware...</td>\n",
       "      <td>Predicting application performance on hardware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>According to one exemplary embodiment, a metho...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10191946</td>\n",
       "      <td>Answering natural language table queries throu...</td>\n",
       "      <td>Answering natural language table queries throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>A user initializes multi-factor authentication...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>10057227</td>\n",
       "      <td>Determination of authentication mechanism</td>\n",
       "      <td>Determination of authentication mechanism. A u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Mechanisms, in a natural language processing (...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10090002</td>\n",
       "      <td>Performing cognitive operations based on an ag...</td>\n",
       "      <td>Performing cognitive operations based on an ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>A system and method for a highly interactive s...</td>\n",
       "      <td>org_HBCbascgAk3Bd6YGl75a</td>\n",
       "      <td>10073843</td>\n",
       "      <td>Method and apparatus for cross-lingual communi...</td>\n",
       "      <td>Method and apparatus for cross-lingual communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>An apparatus is described. The apparatus inclu...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>10129477</td>\n",
       "      <td>Smart image sensor having integrated memory an...</td>\n",
       "      <td>Smart image sensor having integrated memory an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>The invention introduces a method for indoor p...</td>\n",
       "      <td>org_2iMfDMxWyTdWHUiYsNin</td>\n",
       "      <td>9995816</td>\n",
       "      <td>Methods for indoor positioning and apparatuses...</td>\n",
       "      <td>Methods for indoor positioning and apparatuses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>A network system customizes communications and...</td>\n",
       "      <td>org_9hSCE3phcxK6iG7SkZ7G</td>\n",
       "      <td>10142222</td>\n",
       "      <td>Customized communications for network systems</td>\n",
       "      <td>Customized communications for network systems....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>A quality-directed adaptive analytic retrainin...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10163061</td>\n",
       "      <td>Quality-directed adaptive analytic retraining</td>\n",
       "      <td>Quality-directed adaptive analytic retraining....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>A device may obtain text to be processed to ex...</td>\n",
       "      <td>org_FMQQGwWD4see8cTUvBeX</td>\n",
       "      <td>10031839</td>\n",
       "      <td>Constraint extraction from natural language te...</td>\n",
       "      <td>Constraint extraction from natural language te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>Technologies are generally described for syste...</td>\n",
       "      <td>org_UvhGr6KydoFfLnHWpAgE</td>\n",
       "      <td>9953271</td>\n",
       "      <td>Generation of weights in machine learning</td>\n",
       "      <td>Generation of weights in machine learning. Tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>A machine may be configured to generate and pr...</td>\n",
       "      <td>org_EilEWQcC6UiqHcSGx9mb</td>\n",
       "      <td>10078489</td>\n",
       "      <td>Voice interface to a social networking service</td>\n",
       "      <td>Voice interface to a social networking service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>A tool for automatic pre-detection of potentia...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>9928160</td>\n",
       "      <td>Automatic pre-detection of potential coding is...</td>\n",
       "      <td>Automatic pre-detection of potential coding is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>One or more context aware processing parameter...</td>\n",
       "      <td>org_ke7Zy0LNN5VwaxuUQeqh</td>\n",
       "      <td>9886954</td>\n",
       "      <td>Context aware hearing optimization engine</td>\n",
       "      <td>Context aware hearing optimization engine. One...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>A method for performing natural language proce...</td>\n",
       "      <td>org_smzwki765kLDF3jl6On4</td>\n",
       "      <td>10140288</td>\n",
       "      <td>Processing text with domain-specific spreading...</td>\n",
       "      <td>Processing text with domain-specific spreading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>An online system trains a machine learning mod...</td>\n",
       "      <td>org_iwO2oOJ6VIBd9fAuP7G6</td>\n",
       "      <td>10129367</td>\n",
       "      <td>Delivering content items using machine learnin...</td>\n",
       "      <td>Delivering content items using machine learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>A machine-learning engine is disclosed that is...</td>\n",
       "      <td>org_mrjO4kRNGCgZ3bl97QbB</td>\n",
       "      <td>10198636</td>\n",
       "      <td>Semantic representation module of a machine-le...</td>\n",
       "      <td>Semantic representation module of a machine-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>For image quality scoring of an image from a m...</td>\n",
       "      <td>org_J6tZaHtxG6uBEMC3qieg</td>\n",
       "      <td>10043088</td>\n",
       "      <td>Image quality score using a deep generative ma...</td>\n",
       "      <td>Image quality score using a deep generative ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Using computer-vision based training informati...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>10169006</td>\n",
       "      <td>Computer-vision based execution of graphical u...</td>\n",
       "      <td>Computer-vision based execution of graphical u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>A computing device executes an application hav...</td>\n",
       "      <td>org_BhFWbZ5cX0tSnPE1cE4T</td>\n",
       "      <td>10089207</td>\n",
       "      <td>Identification of software phases using machin...</td>\n",
       "      <td>Identification of software phases using machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_FMQQGwWD4see8cTUvBeX</td>\n",
       "      <td>10073763</td>\n",
       "      <td>Touchless testing platform</td>\n",
       "      <td>Touchless testing platform. Methods, systems, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>A method of digitizing a well log includes ide...</td>\n",
       "      <td>org_5cVsTq3qEkKQWsj9b3Gj</td>\n",
       "      <td>10095983</td>\n",
       "      <td>System and method for well trace analysis</td>\n",
       "      <td>System and method for well trace analysis. A m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>A method, system, and computer program product...</td>\n",
       "      <td>org_EONQL1O7u6z1SVrg6jyr</td>\n",
       "      <td>9971766</td>\n",
       "      <td>Conversational agent</td>\n",
       "      <td>Conversational agent. A method, system, and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Features are disclosed for generating predicti...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>10049656</td>\n",
       "      <td>Generation of predictive natural language proc...</td>\n",
       "      <td>Generation of predictive natural language proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>A security platform employs a variety techniqu...</td>\n",
       "      <td>org_FnwHVjRQWWObkacCtbJp</td>\n",
       "      <td>10063570</td>\n",
       "      <td>Probabilistic suffix trees for network securit...</td>\n",
       "      <td>Probabilistic suffix trees for network securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>The present embodiments relate to machine lear...</td>\n",
       "      <td>org_J6tZaHtxG6uBEMC3qieg</td>\n",
       "      <td>9922272</td>\n",
       "      <td>Deep similarity learning for multimodal medica...</td>\n",
       "      <td>Deep similarity learning for multimodal medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>A method and system learns new forms to be inc...</td>\n",
       "      <td>org_U6feekQVzPuPglpgKSBc</td>\n",
       "      <td>10140277</td>\n",
       "      <td>System and method for selecting data sample gr...</td>\n",
       "      <td>System and method for selecting data sample gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>10127909</td>\n",
       "      <td>Query rewrite corrections</td>\n",
       "      <td>Query rewrite corrections. Methods, systems, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Methods, systems, and non-transitory, computer...</td>\n",
       "      <td>org_Y5Tht7WZIuEYKAJwDAZQ</td>\n",
       "      <td>10162315</td>\n",
       "      <td>Process control system using typical and adapt...</td>\n",
       "      <td>Process control system using typical and adapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Techniques for creating a template to be used ...</td>\n",
       "      <td>org_b3O3wGAxEtC5OkGC8AmD</td>\n",
       "      <td>10037317</td>\n",
       "      <td>Techniques for automatic generation of natural...</td>\n",
       "      <td>Techniques for automatic generation of natural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Some embodiments include a machine learner pla...</td>\n",
       "      <td>org_iwO2oOJ6VIBd9fAuP7G6</td>\n",
       "      <td>9996804</td>\n",
       "      <td>Machine learning model tracking platform</td>\n",
       "      <td>Machine learning model tracking platform. Some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Various embodiments contemplate systems and me...</td>\n",
       "      <td>org_VYf8AgH3ANL4z5Pbi6bR</td>\n",
       "      <td>10170114</td>\n",
       "      <td>Systems and methods for adaptive proper name e...</td>\n",
       "      <td>Systems and methods for adaptive proper name e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>A machine learning system for evaluating at le...</td>\n",
       "      <td>org_u3NTgGuhUeP31UUvruii</td>\n",
       "      <td>9953272</td>\n",
       "      <td>Machine learning system for assessing heart va...</td>\n",
       "      <td>Machine learning system for assessing heart va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>In a computer-implemented method for endpoint ...</td>\n",
       "      <td>org_K1Ir53a8yngRkTJ1TB7F</td>\n",
       "      <td>10089384</td>\n",
       "      <td>Machine learning-derived universal connector</td>\n",
       "      <td>Machine learning-derived universal connector. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>System component failure diagnosis is provided...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>9916194</td>\n",
       "      <td>System component failure diagnosis</td>\n",
       "      <td>System component failure diagnosis. System com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>A system, an apparatus or a process may be con...</td>\n",
       "      <td>org_7vW20m79oYDc4Nw7eyLQ</td>\n",
       "      <td>10048683</td>\n",
       "      <td>Machine learning systems and techniques to opt...</td>\n",
       "      <td>Machine learning systems and techniques to opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>Provided are techniques for receiving a scanne...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>9910841</td>\n",
       "      <td>Annotation data generation and overlay for enh...</td>\n",
       "      <td>Annotation data generation and overlay for enh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>A system and method for management of network ...</td>\n",
       "      <td>org_krHJCqMYeOjju2UJXges</td>\n",
       "      <td>9967188</td>\n",
       "      <td>Network traffic flow management using machine ...</td>\n",
       "      <td>Network traffic flow management using machine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>A baggage system includes a plurality of RFID ...</td>\n",
       "      <td>org_LlVzra65CGltaaWVQFt1</td>\n",
       "      <td>10192636</td>\n",
       "      <td>Baggage system, RFID chip, server and method f...</td>\n",
       "      <td>Baggage system, RFID chip, server and method f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>In a general aspect, motion in a space can be ...</td>\n",
       "      <td>org_3Uq1qNP77dF7x9CIWpOV</td>\n",
       "      <td>10108903</td>\n",
       "      <td>Motion detection based on machine learning of ...</td>\n",
       "      <td>Motion detection based on machine learning of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       patent_abstract  \\\n",
       "140  An electronic device can receive user input vi...   \n",
       "844  A graymail detection and filtering system pred...   \n",
       "843  A computer system automatically generates serv...   \n",
       "305  A system may include multiple personal data so...   \n",
       "173  The present disclosure relates to a system and...   \n",
       "715  Methods and a system are provided that is perf...   \n",
       "566  A machine learning model is trained by definin...   \n",
       "152  A data analysis system stores in-memory repres...   \n",
       "851  A computer-implemented method, a processing pi...   \n",
       "503  The invention provides an autonomous vehicle c...   \n",
       "225  A method and system for teaching an object of ...   \n",
       "227  Technology for link parameter identification i...   \n",
       "584  Methods, devices, systems, and non-transitory ...   \n",
       "291  A security platform employs a variety techniqu...   \n",
       "987  Mined semantic analysis techniques (MSA) inclu...   \n",
       "298  First content containing a plurality of list i...   \n",
       "479  The present disclosure is directed to extracti...   \n",
       "925  The disclosed solution uses machine learning-b...   \n",
       "751  An acoustic array system for anomaly detection...   \n",
       "344  Systems and methods are provided for estimatin...   \n",
       "635  Predicting program performance on hardware dev...   \n",
       "128  According to one exemplary embodiment, a metho...   \n",
       "571  A user initializes multi-factor authentication...   \n",
       "461  Mechanisms, in a natural language processing (...   \n",
       "510  A system and method for a highly interactive s...   \n",
       "353  An apparatus is described. The apparatus inclu...   \n",
       "719  The invention introduces a method for indoor p...   \n",
       "316  A network system customizes communications and...   \n",
       "243  A quality-directed adaptive analytic retrainin...   \n",
       "630  A device may obtain text to be processed to ex...   \n",
       "..                                                 ...   \n",
       "836  Technologies are generally described for syste...   \n",
       "485  A machine may be configured to generate and pr...   \n",
       "880  A tool for automatic pre-detection of potentia...   \n",
       "978  One or more context aware processing parameter...   \n",
       "300  A method for performing natural language proce...   \n",
       "351  An online system trains a machine learning mod...   \n",
       "116  A machine-learning engine is disclosed that is...   \n",
       "607  For image quality scoring of an image from a m...   \n",
       "198  Using computer-vision based training informati...   \n",
       "452  A computing device executes an application hav...   \n",
       "504  Methods, systems, and apparatus, including com...   \n",
       "438  A method of digitizing a well log includes ide...   \n",
       "781  A method, system, and computer program product...   \n",
       "587  Features are disclosed for generating predicti...   \n",
       "552  A security platform employs a variety techniqu...   \n",
       "900  The present embodiments relate to machine lear...   \n",
       "299  A method and system learns new forms to be inc...   \n",
       "348  Methods, systems, and apparatus, including com...   \n",
       "232  Methods, systems, and non-transitory, computer...   \n",
       "618  Techniques for creating a template to be used ...   \n",
       "730  Some embodiments include a machine learner pla...   \n",
       "223  Various embodiments contemplate systems and me...   \n",
       "837  A machine learning system for evaluating at le...   \n",
       "455  In a computer-implemented method for endpoint ...   \n",
       "912  System component failure diagnosis is provided...   \n",
       "576  A system, an apparatus or a process may be con...   \n",
       "924  Provided are techniques for receiving a scanne...   \n",
       "809  A system and method for management of network ...   \n",
       "141  A baggage system includes a plurality of RFID ...   \n",
       "395  In a general aspect, motion in a space can be ...   \n",
       "\n",
       "    patent_firstnamed_assignee_id patent_number  \\\n",
       "140      org_EilEWQcC6UiqHcSGx9mb      10192549   \n",
       "844      org_hZHBoHvjQMoGbVbMF740       9954805   \n",
       "843      org_EilEWQcC6UiqHcSGx9mb       9954746   \n",
       "305      org_oBgJHolxfEg0kgVOfKYg      10140322   \n",
       "173      org_U6feekQVzPuPglpgKSBc      10175979   \n",
       "715      org_q9Bn28RHhpYrQjKvraAH      10003923   \n",
       "566      org_8O8xQifxyiW5pZB2KuDx      10055675   \n",
       "152      org_uSkGGmX0kIBgxQmYxLGK      10185930   \n",
       "851      org_FMQQGwWD4see8cTUvBeX       9946924   \n",
       "503      org_UfP75xYv5uGvK5xNfkLe      10073462   \n",
       "225      org_q9Bn28RHhpYrQjKvraAH      10170117   \n",
       "227      org_S4ohigZQayeHnhlzllnG      10171161   \n",
       "584      org_BMNBDoKtp8BLidFVt55K      10049327   \n",
       "291      org_FnwHVjRQWWObkacCtbJp      10148677   \n",
       "987      org_oGjQ7OAz5h3J1vYCd4s6       9880999   \n",
       "298      org_q9Bn28RHhpYrQjKvraAH      10140273   \n",
       "479      org_6LK9HJqqm2RNBebbySEF      10084725   \n",
       "925      org_m0hwKu6AOhMMpHWb6CrO       9910845   \n",
       "751      org_jgiwLxLF4g3IhRpgbvYS       9984543   \n",
       "344      org_oeYwik2sRVlspT4VbRYA      10127496   \n",
       "635      org_q9Bn28RHhpYrQjKvraAH      10032114   \n",
       "128      org_q9Bn28RHhpYrQjKvraAH      10191946   \n",
       "571      org_Vbc6obpnxWM42d0HjlXY      10057227   \n",
       "461      org_q9Bn28RHhpYrQjKvraAH      10090002   \n",
       "510      org_HBCbascgAk3Bd6YGl75a      10073843   \n",
       "353      org_p6ofWD2xFNSnyYkj6wpA      10129477   \n",
       "719      org_2iMfDMxWyTdWHUiYsNin       9995816   \n",
       "316      org_9hSCE3phcxK6iG7SkZ7G      10142222   \n",
       "243      org_q9Bn28RHhpYrQjKvraAH      10163061   \n",
       "630      org_FMQQGwWD4see8cTUvBeX      10031839   \n",
       "..                            ...           ...   \n",
       "836      org_UvhGr6KydoFfLnHWpAgE       9953271   \n",
       "485      org_EilEWQcC6UiqHcSGx9mb      10078489   \n",
       "880      org_q9Bn28RHhpYrQjKvraAH       9928160   \n",
       "978      org_ke7Zy0LNN5VwaxuUQeqh       9886954   \n",
       "300      org_smzwki765kLDF3jl6On4      10140288   \n",
       "351      org_iwO2oOJ6VIBd9fAuP7G6      10129367   \n",
       "116      org_mrjO4kRNGCgZ3bl97QbB      10198636   \n",
       "607      org_J6tZaHtxG6uBEMC3qieg      10043088   \n",
       "198      org_q9Bn28RHhpYrQjKvraAH      10169006   \n",
       "452      org_BhFWbZ5cX0tSnPE1cE4T      10089207   \n",
       "504      org_FMQQGwWD4see8cTUvBeX      10073763   \n",
       "438      org_5cVsTq3qEkKQWsj9b3Gj      10095983   \n",
       "781      org_EONQL1O7u6z1SVrg6jyr       9971766   \n",
       "587      org_Vbc6obpnxWM42d0HjlXY      10049656   \n",
       "552      org_FnwHVjRQWWObkacCtbJp      10063570   \n",
       "900      org_J6tZaHtxG6uBEMC3qieg       9922272   \n",
       "299      org_U6feekQVzPuPglpgKSBc      10140277   \n",
       "348      org_p6ofWD2xFNSnyYkj6wpA      10127909   \n",
       "232      org_Y5Tht7WZIuEYKAJwDAZQ      10162315   \n",
       "618      org_b3O3wGAxEtC5OkGC8AmD      10037317   \n",
       "730      org_iwO2oOJ6VIBd9fAuP7G6       9996804   \n",
       "223      org_VYf8AgH3ANL4z5Pbi6bR      10170114   \n",
       "837      org_u3NTgGuhUeP31UUvruii       9953272   \n",
       "455      org_K1Ir53a8yngRkTJ1TB7F      10089384   \n",
       "912      org_q9Bn28RHhpYrQjKvraAH       9916194   \n",
       "576      org_7vW20m79oYDc4Nw7eyLQ      10048683   \n",
       "924      org_q9Bn28RHhpYrQjKvraAH       9910841   \n",
       "809      org_krHJCqMYeOjju2UJXges       9967188   \n",
       "141      org_LlVzra65CGltaaWVQFt1      10192636   \n",
       "395      org_3Uq1qNP77dF7x9CIWpOV      10108903   \n",
       "\n",
       "                                          patent_title  \\\n",
       "140  Extending digital personal assistant action pr...   \n",
       "844       Graymail filtering-based on user preferences   \n",
       "843  Automatically generating service documentation...   \n",
       "305  Tools and techniques for extracting knowledge ...   \n",
       "173  Defect ownership assignment system and predict...   \n",
       "715  Location context inference based on user mobil...   \n",
       "566  Training algorithm for collision avoidance usi...   \n",
       "152  Collaboration using shared documents for proce...   \n",
       "851  System and method for automating information a...   \n",
       "503  Autonomous vehicle with improved visual detect...   \n",
       "225  User-guided teaching an object of a deictic re...   \n",
       "227  Machine learning for link parameter identifica...   \n",
       "584  Application characterization for machine learn...   \n",
       "291  Model training and deployment in complex event...   \n",
       "987  Natural language relatedness tool using mined ...   \n",
       "298   List manipulation in natural language processing   \n",
       "479  Extracting features from a NoC for machine lea...   \n",
       "925                   Call flow and discourse analysis   \n",
       "751                Anomaly detection system and method   \n",
       "344      System and method for estimating arrival time   \n",
       "635  Predicting application performance on hardware...   \n",
       "128  Answering natural language table queries throu...   \n",
       "571          Determination of authentication mechanism   \n",
       "461  Performing cognitive operations based on an ag...   \n",
       "510  Method and apparatus for cross-lingual communi...   \n",
       "353  Smart image sensor having integrated memory an...   \n",
       "719  Methods for indoor positioning and apparatuses...   \n",
       "316      Customized communications for network systems   \n",
       "243      Quality-directed adaptive analytic retraining   \n",
       "630  Constraint extraction from natural language te...   \n",
       "..                                                 ...   \n",
       "836          Generation of weights in machine learning   \n",
       "485     Voice interface to a social networking service   \n",
       "880  Automatic pre-detection of potential coding is...   \n",
       "978          Context aware hearing optimization engine   \n",
       "300  Processing text with domain-specific spreading...   \n",
       "351  Delivering content items using machine learnin...   \n",
       "116  Semantic representation module of a machine-le...   \n",
       "607  Image quality score using a deep generative ma...   \n",
       "198  Computer-vision based execution of graphical u...   \n",
       "452  Identification of software phases using machin...   \n",
       "504                         Touchless testing platform   \n",
       "438          System and method for well trace analysis   \n",
       "781                               Conversational agent   \n",
       "587  Generation of predictive natural language proc...   \n",
       "552  Probabilistic suffix trees for network securit...   \n",
       "900  Deep similarity learning for multimodal medica...   \n",
       "299  System and method for selecting data sample gr...   \n",
       "348                          Query rewrite corrections   \n",
       "232  Process control system using typical and adapt...   \n",
       "618  Techniques for automatic generation of natural...   \n",
       "730           Machine learning model tracking platform   \n",
       "223  Systems and methods for adaptive proper name e...   \n",
       "837  Machine learning system for assessing heart va...   \n",
       "455       Machine learning-derived universal connector   \n",
       "912                 System component failure diagnosis   \n",
       "576  Machine learning systems and techniques to opt...   \n",
       "924  Annotation data generation and overlay for enh...   \n",
       "809  Network traffic flow management using machine ...   \n",
       "141  Baggage system, RFID chip, server and method f...   \n",
       "395  Motion detection based on machine learning of ...   \n",
       "\n",
       "                                 patent_title_abstract  \n",
       "140  Extending digital personal assistant action pr...  \n",
       "844  Graymail filtering-based on user preferences. ...  \n",
       "843  Automatically generating service documentation...  \n",
       "305  Tools and techniques for extracting knowledge ...  \n",
       "173  Defect ownership assignment system and predict...  \n",
       "715  Location context inference based on user mobil...  \n",
       "566  Training algorithm for collision avoidance usi...  \n",
       "152  Collaboration using shared documents for proce...  \n",
       "851  System and method for automating information a...  \n",
       "503  Autonomous vehicle with improved visual detect...  \n",
       "225  User-guided teaching an object of a deictic re...  \n",
       "227  Machine learning for link parameter identifica...  \n",
       "584  Application characterization for machine learn...  \n",
       "291  Model training and deployment in complex event...  \n",
       "987  Natural language relatedness tool using mined ...  \n",
       "298  List manipulation in natural language processi...  \n",
       "479  Extracting features from a NoC for machine lea...  \n",
       "925  Call flow and discourse analysis. The disclose...  \n",
       "751  Anomaly detection system and method. An acoust...  \n",
       "344  System and method for estimating arrival time....  \n",
       "635  Predicting application performance on hardware...  \n",
       "128  Answering natural language table queries throu...  \n",
       "571  Determination of authentication mechanism. A u...  \n",
       "461  Performing cognitive operations based on an ag...  \n",
       "510  Method and apparatus for cross-lingual communi...  \n",
       "353  Smart image sensor having integrated memory an...  \n",
       "719  Methods for indoor positioning and apparatuses...  \n",
       "316  Customized communications for network systems....  \n",
       "243  Quality-directed adaptive analytic retraining....  \n",
       "630  Constraint extraction from natural language te...  \n",
       "..                                                 ...  \n",
       "836  Generation of weights in machine learning. Tec...  \n",
       "485  Voice interface to a social networking service...  \n",
       "880  Automatic pre-detection of potential coding is...  \n",
       "978  Context aware hearing optimization engine. One...  \n",
       "300  Processing text with domain-specific spreading...  \n",
       "351  Delivering content items using machine learnin...  \n",
       "116  Semantic representation module of a machine-le...  \n",
       "607  Image quality score using a deep generative ma...  \n",
       "198  Computer-vision based execution of graphical u...  \n",
       "452  Identification of software phases using machin...  \n",
       "504  Touchless testing platform. Methods, systems, ...  \n",
       "438  System and method for well trace analysis. A m...  \n",
       "781  Conversational agent. A method, system, and co...  \n",
       "587  Generation of predictive natural language proc...  \n",
       "552  Probabilistic suffix trees for network securit...  \n",
       "900  Deep similarity learning for multimodal medica...  \n",
       "299  System and method for selecting data sample gr...  \n",
       "348  Query rewrite corrections. Methods, systems, a...  \n",
       "232  Process control system using typical and adapt...  \n",
       "618  Techniques for automatic generation of natural...  \n",
       "730  Machine learning model tracking platform. Some...  \n",
       "223  Systems and methods for adaptive proper name e...  \n",
       "837  Machine learning system for assessing heart va...  \n",
       "455  Machine learning-derived universal connector. ...  \n",
       "912  System component failure diagnosis. System com...  \n",
       "576  Machine learning systems and techniques to opt...  \n",
       "924  Annotation data generation and overlay for enh...  \n",
       "809  Network traffic flow management using machine ...  \n",
       "141  Baggage system, RFID chip, server and method f...  \n",
       "395  Motion detection based on machine learning of ...  \n",
       "\n",
       "[195 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf vec requires list, not just string\n",
    "unseen_data = test_text\n",
    "unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 4924)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_tfidf = tfidf.transform(unseen_data['patent_title_abstract'])\n",
    "unseen_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7882dd8c198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# take user input of straing and output most similar documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# get idx of patent_number that matches text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_string\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosine_sim' is not defined"
     ]
    }
   ],
   "source": [
    "# take user input of string and output most similar documents\n",
    "def get_recommendations(string, cosine_sim=cosine_sim):\n",
    "    # get idx of patent_number that matches text\n",
    "    idx = train_text['patent_title_abstract']\n",
    "\n",
    "    # calculate pairwise similarity scores of all patents with given patent\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # sort patents based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # get scores of 10 most similar patents\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # get patent indices\n",
    "    patent_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return top 10 most similar documents\n",
    "    return df_1000_1['patent_title_abstract'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #2 - Apply K means clustering to distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmresult = km.fit(tfidf_matrix).predict(unseen_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmresult_p = km.predict(unseen_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmresult_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
