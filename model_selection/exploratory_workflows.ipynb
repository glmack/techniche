{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniche - Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import mmcorpus\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import AuthorTopicModel, atmodel\n",
    "from gensim.test.utils import common_dictionary, datapath, temporary_file\n",
    "from smart_open import smart_open\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, punkt, RegexpTokenizer, wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import calendar\n",
    "import sys\n",
    "\n",
    "from test_model import tokenize_docs, clean_docs, lower_words, remove_stopwords, get_topics  # TODO (Lee) convert_bytes\n",
    "\n",
    "from smart_open import smart_open\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download stop words from nltk and language package from spacy\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data from PatentsView API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patents endpoint\n",
    "endpoint_url = 'http://www.patentsview.org/api/patents/query'\n",
    "\n",
    "# build list of possible fields that endpoint request will return\n",
    "df = pd.read_excel(\"/Users/lee/Documents/techniche/techniche/data/patents_view_patents_fields.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "pat_fields = df.api_field_name.values.tolist()\n",
    "# pat_fields = ['appcit_app_number', 'appcit_category', 'appcit_date', 'appcit_kind', 'appcit_sequence',\n",
    "#      'app_country', 'app_date', 'app_number', 'app_type', 'assignee_city', 'assignee_country',\n",
    "#      'assignee_county', 'assignee_county_fips', 'assignee_first_name', 'assignee_first_seen_date',\n",
    "#      'assignee_id', 'assignee_last_name', 'assignee_last_seen_date', 'assignee_lastknown_city',\n",
    "#      'assignee_lastknown_country', 'assignee_lastknown_latitude', 'assignee_lastknown_location_id',\n",
    "#      'assignee_lastknown_longitude', 'assignee_lastknown_state', 'assignee_latitude', \n",
    "#      'assignee_location_id', 'assignee_longitude', 'assignee_organization', 'assignee_sequence',\n",
    "#      'assignee_state', 'assignee_state_fips', 'assignee_total_num_inventors', \n",
    "#      'assignee_total_num_patents', 'assignee_type', 'cited_patent_category', 'cited_patent_date',\n",
    "#      'cited_patent_kind', 'cited_patent_number', 'cited_patent_sequence', 'cited_patent_title',\n",
    "#      'citedby_patent_category', 'citedby_patent_date', 'citedby_patent_kind',\n",
    "#      'citedby_patent_number', 'citedby_patent_title', 'cpc_category', 'cpc_first_seen_date',\n",
    "#      'cpc_group_id', 'cpc_group_title', 'cpc_last_seen_date', 'cpc_section_id', 'cpc_sequence',\n",
    "#      'cpc_subgroup_id', 'cpc_subgroup_title', 'cpc_subsection_id', 'cpc_subsection_title',\n",
    "#      'cpc_total_num_assignees', 'cpc_total_num_inventors', 'cpc_total_num_patents',\n",
    "#      'detail_desc_length', 'examiner_first_name', 'examiner_id', 'examiner_last_name',\n",
    "#      'examiner_role', 'examiner_group', 'forprior_country', 'forprior_date', 'forprior_docnumber',\n",
    "#      'forprior_kind', 'forprior_sequence', 'govint_contract_award_number', 'govint_org_id',\n",
    "#      'govint_org_level_one', 'govint_org_level_two', 'govint_org_level_three', 'govint_org_name',\n",
    "#      'govint_raw_statement', 'inventor_city', 'inventor_country', 'inventor_county',\n",
    "#      'inventor_county_fips', 'inventor_first_name', 'inventor_first_seen_date', 'inventor_id',\n",
    "#      'inventor_last_name', 'inventor_last_seen_date', 'inventor_lastknown_city',\n",
    "#      'inventor_lastknown_country', 'inventor_lastknown_latitude', 'inventor_lastknown_location_id',\n",
    "#      'inventor_lastknown_longitude', 'inventor_lastknown_state', 'inventor_latitude',\n",
    "#      'inventor_location_id', 'inventor_longitude', 'inventor_sequence', 'inventor_state',\n",
    "#      'inventor_state_fips', 'inventor_total_num_patents', 'ipc_action_date', 'ipc_class',\n",
    "#      'ipc_classification_data_source', 'ipc_classification_value', 'ipc_first_seen_date',\n",
    "#      'ipc_last_seen_date', 'ipc_main_group', 'ipc_section', 'ipc_sequence', 'ipc_subclass',\n",
    "#      'ipc_subgroup', 'ipc_symbol_position', 'ipc_total_num_assignees', 'ipc_total_num_inventors',\n",
    "#      'ipc_version_indicator', 'lawyer_first_name', 'lawyer_first_seen_date', 'lawyer_id',\n",
    "#      'lawyer_last_name', 'lawyer_last_seen_date', 'lawyer_organization', 'lawyer_sequence',\n",
    "#      'lawyer_total_num_assignees', 'lawyer_total_num_inventors', 'lawyer_total_num_patents',\n",
    "#      'nber_category_id', 'nber_category_title', 'nber_first_seen_date', 'nber_last_seen_date',\n",
    "#      'nber_subcategory_id', 'nber_subcategory_title', 'nber_total_num_assignees',\n",
    "#      'nber_total_num_inventors', 'nber_total_num_patents', 'patent_abstract',\n",
    "#      'patent_average_processing_time', 'patent_date', 'patent_firstnamed_assignee_city',\n",
    "#      'patent_firstnamed_assignee_country', 'patent_firstnamed_assignee_id', \n",
    "#      'patent_firstnamed_assignee_latitude', 'patent_firstnamed_assignee_location_id',\n",
    "#      'patent_firstnamed_assignee_longitude', 'patent_firstnamed_assignee_state',\n",
    "#      'patent_firstnamed_inventor_city', 'patent_firstnamed_inventor_country',\n",
    "#      'patent_firstnamed_inventor_id', 'patent_firstnamed_inventor_latitude',\n",
    "#      'patent_firstnamed_inventor_location_id', 'patent_firstnamed_inventor_longitude',\n",
    "#      'patent_firstnamed_inventor_state', 'patent_kind', 'patent_num_cited_by_us_patents',\n",
    "#      'patent_num_claims', 'patent_num_combined_citations', 'patent_num_foreign_citations',\n",
    "#      'patent_num_us_application_citations', 'patent_num_us_patent_citations', 'patent_number',\n",
    "#      'patent_processing_time', 'patent_title', 'patent_type', 'patent_year', 'pct_102_date',\n",
    "#      'pct_371_date', 'pct_date', 'pct_docnumber', 'pct_doctype', 'pct_kind',\n",
    "#      'rawinventor_first_name', 'rawinventor_last_name', 'uspc_first_seen_date',\n",
    "#      'uspc_last_seen_date', 'uspc_mainclass_id', 'uspc_mainclass_title', 'uspc_sequence',\n",
    "#      'uspc_subclass_id', 'uspc_subclass_title', 'uspc_total_num_assignees', \n",
    "#      'uspc_total_num_inventors', 'uspc_total_num_patents', 'wipo_field_id','wipo_field_title',\n",
    "#      'wipo_sector_title','wipo_sequence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: 200\n",
      "patents on current page: 100 ; total patents: 2482\n"
     ]
    }
   ],
   "source": [
    "# build query - initial small dataset\n",
    "query={\"_or\":[{\"_text_phrase\":{\"patent_title\":\"natural language\"}},{\"_text_phrase\":{\"patent_abstract\":\"natural language\"}}]}\n",
    "fields=pat_fields\n",
    "options={\"per_page\":100}\n",
    "sort=[{\"patent_date\":\"desc\"}]\n",
    "\n",
    "params={'q': json.dumps(query),\n",
    "        'f': json.dumps(fields),\n",
    "        'o': json.dumps(options),\n",
    "        's': json.dumps(sort)}\n",
    "\n",
    "# request and results\n",
    "response = requests.get(endpoint_url, params=params)\n",
    "status = response.status_code\n",
    "print(\"status:\", status)\n",
    "results = response.json()\n",
    "count = results.get(\"count\")\n",
    "total_pats = results.get(\"total_patent_count\")\n",
    "print(\"patents on current page:\",count,';', \"total patents:\",total_pats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code: 200 ; reason: OK\n",
      "total_patent_count: 2482 ; patents_per_page: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCs</th>\n",
       "      <th>application_citations</th>\n",
       "      <th>applications</th>\n",
       "      <th>assignees</th>\n",
       "      <th>cited_patents</th>\n",
       "      <th>citedby_patents</th>\n",
       "      <th>cpcs</th>\n",
       "      <th>detail_desc_length</th>\n",
       "      <th>examiners</th>\n",
       "      <th>foreign_priority</th>\n",
       "      <th>gov_interests</th>\n",
       "      <th>inventors</th>\n",
       "      <th>lawyers</th>\n",
       "      <th>nbers</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_average_processing_time</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_firstnamed_assignee_city</th>\n",
       "      <th>patent_firstnamed_assignee_country</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_firstnamed_assignee_latitude</th>\n",
       "      <th>patent_firstnamed_assignee_location_id</th>\n",
       "      <th>patent_firstnamed_assignee_longitude</th>\n",
       "      <th>patent_firstnamed_assignee_state</th>\n",
       "      <th>patent_firstnamed_inventor_city</th>\n",
       "      <th>patent_firstnamed_inventor_country</th>\n",
       "      <th>patent_firstnamed_inventor_id</th>\n",
       "      <th>patent_firstnamed_inventor_latitude</th>\n",
       "      <th>patent_firstnamed_inventor_location_id</th>\n",
       "      <th>patent_firstnamed_inventor_longitude</th>\n",
       "      <th>patent_firstnamed_inventor_state</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_num_cited_by_us_patents</th>\n",
       "      <th>patent_num_claims</th>\n",
       "      <th>patent_num_combined_citations</th>\n",
       "      <th>patent_num_foreign_citations</th>\n",
       "      <th>patent_num_us_application_citations</th>\n",
       "      <th>patent_num_us_patent_citations</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_processing_time</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>pct_data</th>\n",
       "      <th>rawinventors</th>\n",
       "      <th>uspcs</th>\n",
       "      <th>wipos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020077823', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2013-07-26...</td>\n",
       "      <td>[{'assignee_city': 'Burlington', 'assignee_cou...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by examiner'...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>11570</td>\n",
       "      <td>[{'examiner_first_name': 'Michael N', 'examine...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Newton', 'inventor_country...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>US</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>42.5047</td>\n",
       "      <td>42.5047|-71.1961</td>\n",
       "      <td>-71.1961</td>\n",
       "      <td>MA</td>\n",
       "      <td>Newton</td>\n",
       "      <td>US</td>\n",
       "      <td>7788103-1</td>\n",
       "      <td>42.3369</td>\n",
       "      <td>42.3369|-71.2097</td>\n",
       "      <td>-71.2097</td>\n",
       "      <td>MA</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>10229106</td>\n",
       "      <td>2055</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Jeffrey N.', 'raw...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020138265', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2017-09-11...</td>\n",
       "      <td>[{'assignee_city': 'Mountain View', 'assignee_...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>28118</td>\n",
       "      <td>[{'examiner_first_name': 'Shreyans A', 'examin...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Adliswil', 'inventor_count...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>US</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>37.3861</td>\n",
       "      <td>37.3861|-122.0828</td>\n",
       "      <td>-122.083</td>\n",
       "      <td>CA</td>\n",
       "      <td>Adliswil</td>\n",
       "      <td>CH</td>\n",
       "      <td>8352247-1</td>\n",
       "      <td>47.3119</td>\n",
       "      <td>47.3119|8.5287</td>\n",
       "      <td>8.5287</td>\n",
       "      <td>None</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10229109</td>\n",
       "      <td>547</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Evgeny A.', 'rawi...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2001/20010029455', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2016-09-28...</td>\n",
       "      <td>[{'assignee_city': 'Seattle', 'assignee_countr...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>119654</td>\n",
       "      <td>[{'examiner_first_name': 'Jialong', 'examiner_...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Seattle', 'inventor_countr...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>9177341-1</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>10229113</td>\n",
       "      <td>895</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Thibault Pierre',...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                IPCs  \\\n",
       "0  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "1  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "2  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "\n",
       "                               application_citations  \\\n",
       "0  [{'appcit_app_number': '2002/20020077823', 'ap...   \n",
       "1  [{'appcit_app_number': '2002/20020138265', 'ap...   \n",
       "2  [{'appcit_app_number': '2001/20010029455', 'ap...   \n",
       "\n",
       "                                        applications  \\\n",
       "0  [{'app_country': 'US', 'app_date': '2013-07-26...   \n",
       "1  [{'app_country': 'US', 'app_date': '2017-09-11...   \n",
       "2  [{'app_country': 'US', 'app_date': '2016-09-28...   \n",
       "\n",
       "                                           assignees  \\\n",
       "0  [{'assignee_city': 'Burlington', 'assignee_cou...   \n",
       "1  [{'assignee_city': 'Mountain View', 'assignee_...   \n",
       "2  [{'assignee_city': 'Seattle', 'assignee_countr...   \n",
       "\n",
       "                                       cited_patents  \\\n",
       "0  [{'cited_patent_category': 'cited by examiner'...   \n",
       "1  [{'cited_patent_category': 'cited by applicant...   \n",
       "2  [{'cited_patent_category': 'cited by applicant...   \n",
       "\n",
       "                                     citedby_patents  \\\n",
       "0  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "1  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "2  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "\n",
       "                                                cpcs detail_desc_length  \\\n",
       "0  [{'cpc_category': None, 'cpc_first_seen_date':...              11570   \n",
       "1  [{'cpc_category': None, 'cpc_first_seen_date':...              28118   \n",
       "2  [{'cpc_category': None, 'cpc_first_seen_date':...             119654   \n",
       "\n",
       "                                           examiners  \\\n",
       "0  [{'examiner_first_name': 'Michael N', 'examine...   \n",
       "1  [{'examiner_first_name': 'Shreyans A', 'examin...   \n",
       "2  [{'examiner_first_name': 'Jialong', 'examiner_...   \n",
       "\n",
       "                                    foreign_priority  \\\n",
       "0  [{'forprior_country': None, 'forprior_date': N...   \n",
       "1  [{'forprior_country': None, 'forprior_date': N...   \n",
       "2  [{'forprior_country': None, 'forprior_date': N...   \n",
       "\n",
       "                                       gov_interests  \\\n",
       "0  [{'govint_contract_award_number': None, 'govin...   \n",
       "1  [{'govint_contract_award_number': None, 'govin...   \n",
       "2  [{'govint_contract_award_number': None, 'govin...   \n",
       "\n",
       "                                           inventors  \\\n",
       "0  [{'inventor_city': 'Newton', 'inventor_country...   \n",
       "1  [{'inventor_city': 'Adliswil', 'inventor_count...   \n",
       "2  [{'inventor_city': 'Seattle', 'inventor_countr...   \n",
       "\n",
       "                                             lawyers  \\\n",
       "0  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "1  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "2  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "\n",
       "                                               nbers  \\\n",
       "0  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "1  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "2  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_average_processing_time patent_date patent_firstnamed_assignee_city  \\\n",
       "0                           None  2019-03-12                      Burlington   \n",
       "1                           None  2019-03-12                   Mountain View   \n",
       "2                           None  2019-03-12                         Seattle   \n",
       "\n",
       "  patent_firstnamed_assignee_country patent_firstnamed_assignee_id  \\\n",
       "0                                 US      org_ID497r4tFbCIaMBjGAST   \n",
       "1                                 US      org_p6ofWD2xFNSnyYkj6wpA   \n",
       "2                                 US      org_Vbc6obpnxWM42d0HjlXY   \n",
       "\n",
       "  patent_firstnamed_assignee_latitude patent_firstnamed_assignee_location_id  \\\n",
       "0                             42.5047                       42.5047|-71.1961   \n",
       "1                             37.3861                      37.3861|-122.0828   \n",
       "2                             47.6064                      47.6064|-122.3308   \n",
       "\n",
       "  patent_firstnamed_assignee_longitude patent_firstnamed_assignee_state  \\\n",
       "0                             -71.1961                               MA   \n",
       "1                             -122.083                               CA   \n",
       "2                             -122.331                               WA   \n",
       "\n",
       "  patent_firstnamed_inventor_city patent_firstnamed_inventor_country  \\\n",
       "0                          Newton                                 US   \n",
       "1                        Adliswil                                 CH   \n",
       "2                         Seattle                                 US   \n",
       "\n",
       "  patent_firstnamed_inventor_id patent_firstnamed_inventor_latitude  \\\n",
       "0                     7788103-1                             42.3369   \n",
       "1                     8352247-1                             47.3119   \n",
       "2                     9177341-1                             47.6064   \n",
       "\n",
       "  patent_firstnamed_inventor_location_id patent_firstnamed_inventor_longitude  \\\n",
       "0                       42.3369|-71.2097                             -71.2097   \n",
       "1                         47.3119|8.5287                               8.5287   \n",
       "2                      47.6064|-122.3308                             -122.331   \n",
       "\n",
       "  patent_firstnamed_inventor_state patent_kind patent_num_cited_by_us_patents  \\\n",
       "0                               MA          B2                              0   \n",
       "1                             None          B1                              0   \n",
       "2                               WA          B1                              0   \n",
       "\n",
       "  patent_num_claims patent_num_combined_citations  \\\n",
       "0                19                            31   \n",
       "1                20                            15   \n",
       "2                20                            74   \n",
       "\n",
       "  patent_num_foreign_citations patent_num_us_application_citations  \\\n",
       "0                            0                                  26   \n",
       "1                            0                                   7   \n",
       "2                            0                                  48   \n",
       "\n",
       "  patent_num_us_patent_citations patent_number patent_processing_time  \\\n",
       "0                              5      10229106                   2055   \n",
       "1                              8      10229109                    547   \n",
       "2                             26      10229113                    895   \n",
       "\n",
       "                                        patent_title patent_type patent_year  \\\n",
       "0  Initializing a workspace for building a natura...     utility        2019   \n",
       "1               Allowing spelling of arbitrary words     utility        2019   \n",
       "2  Leveraging content dimensions during the trans...     utility        2019   \n",
       "\n",
       "                                            pct_data  \\\n",
       "0  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "1  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "2  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "\n",
       "                                        rawinventors  \\\n",
       "0  [{'rawinventor_first_name': 'Jeffrey N.', 'raw...   \n",
       "1  [{'rawinventor_first_name': 'Evgeny A.', 'rawi...   \n",
       "2  [{'rawinventor_first_name': 'Thibault Pierre',...   \n",
       "\n",
       "                                               uspcs  \\\n",
       "0  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "1  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "2  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "\n",
       "                                               wipos  \n",
       "0  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "1  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "2  [{'wipo_field_id': None, 'wipo_field_title': N...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract metadata from response\n",
    "print(\"status code:\", response.status_code,';', \"reason:\", response.reason)\n",
    "total_patent_count = results[\"total_patent_count\"]\n",
    "patents_per_page = results['count']\n",
    "print(\"total_patent_count:\",total_patent_count,';', \"patents_per_page:\", patents_per_page)\n",
    "\n",
    "# extract data from response\n",
    "data_resp = results['patents']\n",
    "# data_resp[0]\n",
    "\n",
    "raw_df = pd.DataFrame(data_resp)\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_firstnamed_assignee_location_id</th>\n",
       "      <th>patent_firstnamed_assignee_latitude</th>\n",
       "      <th>patent_firstnamed_assignee_longitude</th>\n",
       "      <th>patent_firstnamed_assignee_city</th>\n",
       "      <th>patent_firstnamed_assignee_state</th>\n",
       "      <th>patent_firstnamed_assignee_country</th>\n",
       "      <th>patent_firstnamed_inventor_id</th>\n",
       "      <th>patent_firstnamed_inventor_location_id</th>\n",
       "      <th>patent_firstnamed_inventor_latitude</th>\n",
       "      <th>patent_firstnamed_inventor_longitude</th>\n",
       "      <th>patent_firstnamed_inventor_city</th>\n",
       "      <th>patent_firstnamed_inventor_state</th>\n",
       "      <th>patent_firstnamed_inventor_country</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>inventors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229106</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>42.5047|-71.1961</td>\n",
       "      <td>42.5047</td>\n",
       "      <td>-71.1961</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>MA</td>\n",
       "      <td>US</td>\n",
       "      <td>7788103-1</td>\n",
       "      <td>42.3369|-71.2097</td>\n",
       "      <td>42.3369</td>\n",
       "      <td>-71.2097</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Newton', 'inventor_country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10229109</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>37.3861|-122.0828</td>\n",
       "      <td>37.3861</td>\n",
       "      <td>-122.083</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>CA</td>\n",
       "      <td>US</td>\n",
       "      <td>8352247-1</td>\n",
       "      <td>47.3119|8.5287</td>\n",
       "      <td>47.3119</td>\n",
       "      <td>8.5287</td>\n",
       "      <td>Adliswil</td>\n",
       "      <td>None</td>\n",
       "      <td>CH</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>[{'inventor_city': 'Adliswil', 'inventor_count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10229113</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>US</td>\n",
       "      <td>9177341-1</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>[{'inventor_city': 'Seattle', 'inventor_countr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_number patent_date  \\\n",
       "0      10229106  2019-03-12   \n",
       "1      10229109  2019-03-12   \n",
       "2      10229113  2019-03-12   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Initializing a workspace for building a natura...   \n",
       "1               Allowing spelling of arbitrary words   \n",
       "2  Leveraging content dimensions during the trans...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_firstnamed_assignee_id patent_firstnamed_assignee_location_id  \\\n",
       "0      org_ID497r4tFbCIaMBjGAST                       42.5047|-71.1961   \n",
       "1      org_p6ofWD2xFNSnyYkj6wpA                      37.3861|-122.0828   \n",
       "2      org_Vbc6obpnxWM42d0HjlXY                      47.6064|-122.3308   \n",
       "\n",
       "  patent_firstnamed_assignee_latitude patent_firstnamed_assignee_longitude  \\\n",
       "0                             42.5047                             -71.1961   \n",
       "1                             37.3861                             -122.083   \n",
       "2                             47.6064                             -122.331   \n",
       "\n",
       "  patent_firstnamed_assignee_city patent_firstnamed_assignee_state  \\\n",
       "0                      Burlington                               MA   \n",
       "1                   Mountain View                               CA   \n",
       "2                         Seattle                               WA   \n",
       "\n",
       "  patent_firstnamed_assignee_country patent_firstnamed_inventor_id  \\\n",
       "0                                 US                     7788103-1   \n",
       "1                                 US                     8352247-1   \n",
       "2                                 US                     9177341-1   \n",
       "\n",
       "  patent_firstnamed_inventor_location_id patent_firstnamed_inventor_latitude  \\\n",
       "0                       42.3369|-71.2097                             42.3369   \n",
       "1                         47.3119|8.5287                             47.3119   \n",
       "2                      47.6064|-122.3308                             47.6064   \n",
       "\n",
       "  patent_firstnamed_inventor_longitude patent_firstnamed_inventor_city  \\\n",
       "0                             -71.2097                          Newton   \n",
       "1                               8.5287                        Adliswil   \n",
       "2                             -122.331                         Seattle   \n",
       "\n",
       "  patent_firstnamed_inventor_state patent_firstnamed_inventor_country  \\\n",
       "0                               MA                                 US   \n",
       "1                             None                                 CH   \n",
       "2                               WA                                 US   \n",
       "\n",
       "  patent_year patent_type patent_kind  \\\n",
       "0        2019     utility          B2   \n",
       "1        2019     utility          B1   \n",
       "2        2019     utility          B1   \n",
       "\n",
       "                                           inventors  \n",
       "0  [{'inventor_city': 'Newton', 'inventor_country...  \n",
       "1  [{'inventor_city': 'Adliswil', 'inventor_count...  \n",
       "2  [{'inventor_city': 'Seattle', 'inventor_countr...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset dataframe - comment/uncomment to include fields\n",
    "df = raw_df[['patent_number', \n",
    "         'patent_date', \n",
    "         'patent_title',\n",
    "         'patent_abstract', \n",
    "         'patent_firstnamed_assignee_id',\n",
    "         'patent_firstnamed_assignee_location_id',\n",
    "         'patent_firstnamed_assignee_latitude',\n",
    "         'patent_firstnamed_assignee_longitude',\n",
    "         'patent_firstnamed_assignee_city',\n",
    "         'patent_firstnamed_assignee_state',\n",
    "         'patent_firstnamed_assignee_country', \n",
    "         'patent_firstnamed_inventor_id',\n",
    "         'patent_firstnamed_inventor_location_id',\n",
    "         'patent_firstnamed_inventor_latitude',\n",
    "         'patent_firstnamed_inventor_longitude',\n",
    "         'patent_firstnamed_inventor_city',\n",
    "         'patent_firstnamed_inventor_state',\n",
    "         'patent_firstnamed_inventor_country',\n",
    "         'patent_year', \n",
    "         'patent_type', \n",
    "         'patent_kind',\n",
    "         'inventors'\n",
    "            ]]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 561 different assignees\n",
    "len(df.patent_firstnamed_assignee_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Initializing a workspace for building a natura...\n",
       "1    Allowing spelling of arbitrary words Methods, ...\n",
       "2    Leveraging content dimensions during the trans...\n",
       "Name: patent_title_abstract, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column that combines the patent title and the patent abstract columns into a single string\n",
    "df['patent_title_abstract'] = df.patent_title + ' ' + df.patent_abstract\n",
    "df.patent_title_abstract.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO (Lee) Partition data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_firstnamed_assignee_location_id</th>\n",
       "      <th>patent_firstnamed_assignee_latitude</th>\n",
       "      <th>patent_firstnamed_assignee_longitude</th>\n",
       "      <th>patent_firstnamed_assignee_city</th>\n",
       "      <th>patent_firstnamed_assignee_state</th>\n",
       "      <th>patent_firstnamed_assignee_country</th>\n",
       "      <th>patent_firstnamed_inventor_id</th>\n",
       "      <th>patent_firstnamed_inventor_location_id</th>\n",
       "      <th>patent_firstnamed_inventor_latitude</th>\n",
       "      <th>patent_firstnamed_inventor_longitude</th>\n",
       "      <th>patent_firstnamed_inventor_city</th>\n",
       "      <th>patent_firstnamed_inventor_state</th>\n",
       "      <th>patent_firstnamed_inventor_country</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>inventors</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10162315</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>Process control system using typical and adapt...</td>\n",
       "      <td>Methods, systems, and non-transitory, computer...</td>\n",
       "      <td>org_Y5Tht7WZIuEYKAJwDAZQ</td>\n",
       "      <td>40.4406|-79.9961</td>\n",
       "      <td>40.4406</td>\n",
       "      <td>-79.9961</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>US</td>\n",
       "      <td>4433971-2</td>\n",
       "      <td>40.6014|-79.76</td>\n",
       "      <td>40.6014</td>\n",
       "      <td>-79.76</td>\n",
       "      <td>Tarentum</td>\n",
       "      <td>PA</td>\n",
       "      <td>US</td>\n",
       "      <td>2018</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Tarentum', 'inventor_count...</td>\n",
       "      <td>Process control system using typical and adapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10168988</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Identifying user preferences and changing sett...</td>\n",
       "      <td>A method, a computer program product, and a co...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>41.1264|-73.7144</td>\n",
       "      <td>41.1264</td>\n",
       "      <td>-73.7144</td>\n",
       "      <td>Armonk</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>10168988-1</td>\n",
       "      <td>39.9042|116.4074</td>\n",
       "      <td>39.9042</td>\n",
       "      <td>116.407</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>None</td>\n",
       "      <td>CN</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Beijing', 'inventor_countr...</td>\n",
       "      <td>Identifying user preferences and changing sett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10169323</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Diagnosing autism spectrum disorder using natu...</td>\n",
       "      <td>Embodiments herein include a natural language ...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>41.1264|-73.7144</td>\n",
       "      <td>41.1264</td>\n",
       "      <td>-73.7144</td>\n",
       "      <td>Armonk</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>8676787-1</td>\n",
       "      <td>44.0692|-92.7556</td>\n",
       "      <td>44.0692</td>\n",
       "      <td>-92.7556</td>\n",
       "      <td>Mantorville</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Rochester', 'inventor_coun...</td>\n",
       "      <td>Diagnosing autism spectrum disorder using natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10169326</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Cognitive reminder notification mechanisms for...</td>\n",
       "      <td>A data processing system generates a result of...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>41.1264|-73.7144</td>\n",
       "      <td>41.1264</td>\n",
       "      <td>-73.7144</td>\n",
       "      <td>Armonk</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>7490098-1</td>\n",
       "      <td>35.8233|-78.8258</td>\n",
       "      <td>35.8233</td>\n",
       "      <td>-78.8258</td>\n",
       "      <td>Morrisville</td>\n",
       "      <td>NC</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Morrisville', 'inventor_co...</td>\n",
       "      <td>Cognitive reminder notification mechanisms for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10169327</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Cognitive reminder notification mechanisms for...</td>\n",
       "      <td>A data processing system generates a result of...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>41.1264|-73.7144</td>\n",
       "      <td>41.1264</td>\n",
       "      <td>-73.7144</td>\n",
       "      <td>Armonk</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>7490098-1</td>\n",
       "      <td>35.8233|-78.8258</td>\n",
       "      <td>35.8233</td>\n",
       "      <td>-78.8258</td>\n",
       "      <td>Morrisville</td>\n",
       "      <td>NC</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Morrisville', 'inventor_co...</td>\n",
       "      <td>Cognitive reminder notification mechanisms for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10229687</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Scalable endpoint-dependent natural language u...</td>\n",
       "      <td>A computer-implemented technique is described ...</td>\n",
       "      <td>org_EilEWQcC6UiqHcSGx9mb</td>\n",
       "      <td>47.6742|-122.1203</td>\n",
       "      <td>47.6742</td>\n",
       "      <td>-122.12</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>US</td>\n",
       "      <td>5712675-3</td>\n",
       "      <td>47.6419|-122.0792</td>\n",
       "      <td>47.6419</td>\n",
       "      <td>-122.079</td>\n",
       "      <td>Sammamish</td>\n",
       "      <td>WA</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Sammamish', 'inventor_coun...</td>\n",
       "      <td>Scalable endpoint-dependent natural language u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10230677</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Identifying an entity associated with an onlin...</td>\n",
       "      <td>An approach is described for identifying an en...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>41.1264|-73.7144</td>\n",
       "      <td>41.1264</td>\n",
       "      <td>-73.7144</td>\n",
       "      <td>Armonk</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>7792904-1</td>\n",
       "      <td>42.6056|-83.15</td>\n",
       "      <td>42.6056</td>\n",
       "      <td>-83.15</td>\n",
       "      <td>Troy</td>\n",
       "      <td>MI</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Sewickley', 'inventor_coun...</td>\n",
       "      <td>Identifying an entity associated with an onlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10230680</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Intelligently splitting text in messages poste...</td>\n",
       "      <td>A method, system and computer program product ...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>41.1264|-73.7144</td>\n",
       "      <td>41.1264</td>\n",
       "      <td>-73.7144</td>\n",
       "      <td>Armonk</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>8380487-1</td>\n",
       "      <td>42.6611|-70.9972</td>\n",
       "      <td>42.6611</td>\n",
       "      <td>-70.9972</td>\n",
       "      <td>Boxford</td>\n",
       "      <td>MA</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Shanghai', 'inventor_count...</td>\n",
       "      <td>Intelligently splitting text in messages poste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10229673</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>System and method for providing follow-up resp...</td>\n",
       "      <td>In certain implementations, follow-up response...</td>\n",
       "      <td>org_9D8x1qL3IRASp6GG7Glu</td>\n",
       "      <td>47.6106|-122.1994</td>\n",
       "      <td>47.6106</td>\n",
       "      <td>-122.199</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>US</td>\n",
       "      <td>7398209-3</td>\n",
       "      <td>47.6106|-122.1994</td>\n",
       "      <td>47.6106</td>\n",
       "      <td>-122.199</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Bellevue', 'inventor_count...</td>\n",
       "      <td>System and method for providing follow-up resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229106</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>42.5047|-71.1961</td>\n",
       "      <td>42.5047</td>\n",
       "      <td>-71.1961</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>MA</td>\n",
       "      <td>US</td>\n",
       "      <td>7788103-1</td>\n",
       "      <td>42.3369|-71.2097</td>\n",
       "      <td>42.3369</td>\n",
       "      <td>-71.2097</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>[{'inventor_city': 'Newton', 'inventor_country...</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patent_number patent_date  \\\n",
       "99      10162315  2018-12-25   \n",
       "78      10168988  2019-01-01   \n",
       "79      10169323  2019-01-01   \n",
       "80      10169326  2019-01-01   \n",
       "81      10169327  2019-01-01   \n",
       "..           ...         ...   \n",
       "11      10229687  2019-03-12   \n",
       "12      10230677  2019-03-12   \n",
       "13      10230680  2019-03-12   \n",
       "7       10229673  2019-03-12   \n",
       "0       10229106  2019-03-12   \n",
       "\n",
       "                                         patent_title  \\\n",
       "99  Process control system using typical and adapt...   \n",
       "78  Identifying user preferences and changing sett...   \n",
       "79  Diagnosing autism spectrum disorder using natu...   \n",
       "80  Cognitive reminder notification mechanisms for...   \n",
       "81  Cognitive reminder notification mechanisms for...   \n",
       "..                                                ...   \n",
       "11  Scalable endpoint-dependent natural language u...   \n",
       "12  Identifying an entity associated with an onlin...   \n",
       "13  Intelligently splitting text in messages poste...   \n",
       "7   System and method for providing follow-up resp...   \n",
       "0   Initializing a workspace for building a natura...   \n",
       "\n",
       "                                      patent_abstract  \\\n",
       "99  Methods, systems, and non-transitory, computer...   \n",
       "78  A method, a computer program product, and a co...   \n",
       "79  Embodiments herein include a natural language ...   \n",
       "80  A data processing system generates a result of...   \n",
       "81  A data processing system generates a result of...   \n",
       "..                                                ...   \n",
       "11  A computer-implemented technique is described ...   \n",
       "12  An approach is described for identifying an en...   \n",
       "13  A method, system and computer program product ...   \n",
       "7   In certain implementations, follow-up response...   \n",
       "0   Designing a natural language understanding (NL...   \n",
       "\n",
       "   patent_firstnamed_assignee_id patent_firstnamed_assignee_location_id  \\\n",
       "99      org_Y5Tht7WZIuEYKAJwDAZQ                       40.4406|-79.9961   \n",
       "78      org_q9Bn28RHhpYrQjKvraAH                       41.1264|-73.7144   \n",
       "79      org_q9Bn28RHhpYrQjKvraAH                       41.1264|-73.7144   \n",
       "80      org_q9Bn28RHhpYrQjKvraAH                       41.1264|-73.7144   \n",
       "81      org_q9Bn28RHhpYrQjKvraAH                       41.1264|-73.7144   \n",
       "..                           ...                                    ...   \n",
       "11      org_EilEWQcC6UiqHcSGx9mb                      47.6742|-122.1203   \n",
       "12      org_q9Bn28RHhpYrQjKvraAH                       41.1264|-73.7144   \n",
       "13      org_q9Bn28RHhpYrQjKvraAH                       41.1264|-73.7144   \n",
       "7       org_9D8x1qL3IRASp6GG7Glu                      47.6106|-122.1994   \n",
       "0       org_ID497r4tFbCIaMBjGAST                       42.5047|-71.1961   \n",
       "\n",
       "   patent_firstnamed_assignee_latitude patent_firstnamed_assignee_longitude  \\\n",
       "99                             40.4406                             -79.9961   \n",
       "78                             41.1264                             -73.7144   \n",
       "79                             41.1264                             -73.7144   \n",
       "80                             41.1264                             -73.7144   \n",
       "81                             41.1264                             -73.7144   \n",
       "..                                 ...                                  ...   \n",
       "11                             47.6742                              -122.12   \n",
       "12                             41.1264                             -73.7144   \n",
       "13                             41.1264                             -73.7144   \n",
       "7                              47.6106                             -122.199   \n",
       "0                              42.5047                             -71.1961   \n",
       "\n",
       "   patent_firstnamed_assignee_city patent_firstnamed_assignee_state  \\\n",
       "99                      Pittsburgh                               PA   \n",
       "78                          Armonk                               NY   \n",
       "79                          Armonk                               NY   \n",
       "80                          Armonk                               NY   \n",
       "81                          Armonk                               NY   \n",
       "..                             ...                              ...   \n",
       "11                         Redmond                               WA   \n",
       "12                          Armonk                               NY   \n",
       "13                          Armonk                               NY   \n",
       "7                         Bellevue                               WA   \n",
       "0                       Burlington                               MA   \n",
       "\n",
       "   patent_firstnamed_assignee_country patent_firstnamed_inventor_id  \\\n",
       "99                                 US                     4433971-2   \n",
       "78                                 US                    10168988-1   \n",
       "79                                 US                     8676787-1   \n",
       "80                                 US                     7490098-1   \n",
       "81                                 US                     7490098-1   \n",
       "..                                ...                           ...   \n",
       "11                                 US                     5712675-3   \n",
       "12                                 US                     7792904-1   \n",
       "13                                 US                     8380487-1   \n",
       "7                                  US                     7398209-3   \n",
       "0                                  US                     7788103-1   \n",
       "\n",
       "   patent_firstnamed_inventor_location_id patent_firstnamed_inventor_latitude  \\\n",
       "99                         40.6014|-79.76                             40.6014   \n",
       "78                       39.9042|116.4074                             39.9042   \n",
       "79                       44.0692|-92.7556                             44.0692   \n",
       "80                       35.8233|-78.8258                             35.8233   \n",
       "81                       35.8233|-78.8258                             35.8233   \n",
       "..                                    ...                                 ...   \n",
       "11                      47.6419|-122.0792                             47.6419   \n",
       "12                         42.6056|-83.15                             42.6056   \n",
       "13                       42.6611|-70.9972                             42.6611   \n",
       "7                       47.6106|-122.1994                             47.6106   \n",
       "0                        42.3369|-71.2097                             42.3369   \n",
       "\n",
       "   patent_firstnamed_inventor_longitude patent_firstnamed_inventor_city  \\\n",
       "99                               -79.76                        Tarentum   \n",
       "78                              116.407                         Beijing   \n",
       "79                             -92.7556                     Mantorville   \n",
       "80                             -78.8258                     Morrisville   \n",
       "81                             -78.8258                     Morrisville   \n",
       "..                                  ...                             ...   \n",
       "11                             -122.079                       Sammamish   \n",
       "12                               -83.15                            Troy   \n",
       "13                             -70.9972                         Boxford   \n",
       "7                              -122.199                        Bellevue   \n",
       "0                              -71.2097                          Newton   \n",
       "\n",
       "   patent_firstnamed_inventor_state patent_firstnamed_inventor_country  \\\n",
       "99                               PA                                 US   \n",
       "78                             None                                 CN   \n",
       "79                               MN                                 US   \n",
       "80                               NC                                 US   \n",
       "81                               NC                                 US   \n",
       "..                              ...                                ...   \n",
       "11                               WA                                 US   \n",
       "12                               MI                                 US   \n",
       "13                               MA                                 US   \n",
       "7                                WA                                 US   \n",
       "0                                MA                                 US   \n",
       "\n",
       "   patent_year patent_type patent_kind  \\\n",
       "99        2018     utility          B2   \n",
       "78        2019     utility          B2   \n",
       "79        2019     utility          B2   \n",
       "80        2019     utility          B2   \n",
       "81        2019     utility          B2   \n",
       "..         ...         ...         ...   \n",
       "11        2019     utility          B2   \n",
       "12        2019     utility          B2   \n",
       "13        2019     utility          B2   \n",
       "7         2019     utility          B2   \n",
       "0         2019     utility          B2   \n",
       "\n",
       "                                            inventors  \\\n",
       "99  [{'inventor_city': 'Tarentum', 'inventor_count...   \n",
       "78  [{'inventor_city': 'Beijing', 'inventor_countr...   \n",
       "79  [{'inventor_city': 'Rochester', 'inventor_coun...   \n",
       "80  [{'inventor_city': 'Morrisville', 'inventor_co...   \n",
       "81  [{'inventor_city': 'Morrisville', 'inventor_co...   \n",
       "..                                                ...   \n",
       "11  [{'inventor_city': 'Sammamish', 'inventor_coun...   \n",
       "12  [{'inventor_city': 'Sewickley', 'inventor_coun...   \n",
       "13  [{'inventor_city': 'Shanghai', 'inventor_count...   \n",
       "7   [{'inventor_city': 'Bellevue', 'inventor_count...   \n",
       "0   [{'inventor_city': 'Newton', 'inventor_country...   \n",
       "\n",
       "                                patent_title_abstract  \n",
       "99  Process control system using typical and adapt...  \n",
       "78  Identifying user preferences and changing sett...  \n",
       "79  Diagnosing autism spectrum disorder using natu...  \n",
       "80  Cognitive reminder notification mechanisms for...  \n",
       "81  Cognitive reminder notification mechanisms for...  \n",
       "..                                                ...  \n",
       "11  Scalable endpoint-dependent natural language u...  \n",
       "12  Identifying an entity associated with an onlin...  \n",
       "13  Intelligently splitting text in messages poste...  \n",
       "7   System and method for providing follow-up resp...  \n",
       "0   Initializing a workspace for building a natura...  \n",
       "\n",
       "[100 rows x 23 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['patent_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Initializing a workspace for building a natural language understanding system Designing a natural language understanding (NLU) model for an application from scratch can be difficult for non-experts. A system can simplify the design process by providing an interface allowing a designer to input example usage sentences and build an NLU model based on presented matches to those example sentences. In one embodiment, a method for initializing a workspace for building an NLU system includes parsing a sample sentence to select at least one candidate stub grammar from among multiple candidate stub grammars. The method can include presenting, to a user, respective representations of the candidate stub grammars selected by the parsing of the sample sentence. The method can include enabling the user to choose one of the respective representations of the candidate stub grammars. The method can include adding to the workspace a stub grammar corresponding to the representation of the candidate stub grammar chosen by the user.',\n",
       " 'Allowing spelling of arbitrary words Methods, systems, and apparatus, including computer programs encoded on computer storage media, for natural language processing. One of the methods includes receiving a first voice input from a user device; generating a first recognition output; receiving a user selection of one or more terms in the first recognition output; receiving a second voice input spelling a correction of the user selection; determining a corrected recognition output for the selected portion; and providing a second recognition output that merges the first recognition output and the corrected recognition output.',\n",
       " 'Leveraging content dimensions during the translation of human-readable languages A content management system (CMS) and a translation management system (TMS) can utilize content dimensions for content items to manage and translate the content items between languages. Machine and human translations of complex dynamic content can also be improved by pre-rendering the content to remove localization-related syntax prior to machine or human translation. Content items can also be scored as to their suitability for localization prior to translation, and translation can be skipped for content items that do not have a sufficiently high score. Semantic and natural language processing (NLP) techniques can also be utilized for content categorization and routing. Translations of content items can also be continuously refined and higher quality re-translated content can be provided in an automated fashion.',\n",
       " 'Using priority scores for iterative precision reduction in structured lookups for questions An approach is provided in which a knowledge manager matches a question to multiple natural language contexts that each correspond to relations associated with entities in a structured resource. The knowledge manager identifies database queries corresponding to the multiple natural language contexts and assigns priority scores to the database queries based upon their relative specificity. In turn, the knowledge manager invokes one of the database queries based upon the assigned priority scores.',\n",
       " 'Systems and methods for generating responses to natural language queries Computer-implemented systems and methods are provided for analyzing and responding to a query from a user. Consistent with certain embodiments, systems and methods are provided for receiving a query from the user and dividing the query into query segments based on a set of grammar rules. Further, systems and methods are provided for selecting a first segment from the query segments, receiving at least one tuple stored in association with the user, selecting a second segment from the at least one tuple. Additionally, systems and methods are provided for receiving information related to the first and second segments, and generating a response to the query based on the received information. In addition, systems and methods are provided for transmitting information to a display device for presenting the response to the user.',\n",
       " 'System for determination of automated response follow-up Aspects include determination of automated response follow-up. A response to a question is received at a response follow-up system. The response follow-up system analyzes the response using natural language processing to identify one or more response terms. The response follow-up system determines one or more follow-up questions based on the one or more response terms. The response follow-up system modifies an aspect of a user interface based on the one or more follow-up questions.',\n",
       " 'System for generation of automated response follow-up Aspects include generation of automated response follow-up. A response to a question is received at a response follow-up system. The response follow-up system analyzes the response using natural language processing to identify one or more response terms. The response follow-up system generates one or more follow-up questions based on the one or more response terms. The response follow-up system modifies an aspect of a user interface based on the one or more follow-up questions.',\n",
       " 'System and method for providing follow-up responses to prior natural language inputs of a user In certain implementations, follow-up responses may be provided for prior natural language inputs of a user. As an example, a natural language input associated with a user may be received at a computer system. A determination of whether information sufficient for providing an adequate response to the natural language input is currently accessible to the computer system may be effectuated. A first response to the natural language input (that indicates that a follow-up response will be provided) may be provided based on a determination that information sufficient for providing an adequate response to the natural language input is not currently accessible. Information sufficient for providing an adequate response to the natural language input may be received. A second response to the natural language input may then be provided based on the received sufficient information.',\n",
       " 'Device-described natural language control A remote device has an associated natural language description that includes a record of commands supported by the remote device. This record of commands includes command names, the command functions to which those names correspond, and natural language strings that are the natural language words or phrases that correspond to the command. A computing device includes a device control module that obtains the natural language description for the remote device and provides the natural language strings to a natural language assistant on the computing device. The natural language assistant monitors the natural language inputs to the computing device, and notifies the device control module when a natural language input matches one of the natural language strings. The device control module uses the natural language description to determine the command name that corresponds to the matching natural language string, and communicates the command name to the remote device.',\n",
       " 'Natural language user interface for computer-aided design systems A natural language user interface for computer-aided design systems (CAD) comprises a natural language command module including a parser, language database and a CAD model analyzer, and a natural language server module including a second, increased capability parser, a second, preferably larger language database and a CAD context database. The CAD model analyzer analyzes and retrieves associated CAD model information related to a parsed voice command and the CAD context database provides specific CAD related contextual information to facilitate parsing and interpreting CAD specific commands. The natural language server program module may also include an artificial intelligence based query generator and communicate through a network or cloud with resource providers such as third party market places or suppliers to generate queries for retrieval of third party supplied information necessary to respond to or execute CAD specific voice commands.',\n",
       " \"Contextual entity resolution Methods and systems for resolving entities using multi-modal functionality are described herein. Voice activated electronic devices may, in some embodiments, be capable of displaying content using a display screen. Contextual metadata representing the content rendered by the display screen may describe entities having similar attributes as an identified intent from natural language understanding processing. When natural language understanding processing attempts to resolve one or more declared slots for a particular intent, matching slots from the contextual metadata may be determined, and the matching entities may be placed in an intent selected context file to be included with the natural language understanding's output data. The output data may be provided to a corresponding application for causing one or more actions to be performed.\",\n",
       " 'Scalable endpoint-dependent natural language understanding A computer-implemented technique is described for processing a linguistic item (e.g., a query) in an efficient and scalable manner. The technique interprets the linguistic item using a language understanding (LU) system in a manner that is based on a particular endpoint mechanism from which the linguistic item originated. The LU system may include an endpoint-independent subsystem, an endpoint-dependent subsystem, and a ranking component. The endpoint-independent subsystem interprets the linguistic item in a manner that is independent of the particular endpoint mechanism. The endpoint-dependent subsystem interprets the linguistic item in a manner that is dependent on the particular endpoint mechanism. The ranking component generates final interpretation results based on intermediate results generated by the endpoint-independent subsystem and the endpoint-dependent subsystem, e.g., by identifying the most likely interpretation of the linguistic item.',\n",
       " 'Identifying an entity associated with an online communication An approach is described for identifying an entity associated with a communication in an online environment. An associated system may include a processor and a memory storing an application program, which, when executed on the processor, performs an operation. The operation may include receiving a communication within the online environment. The communication may include a plurality of sequential messages. The operation further may include facilitating parsing, via natural language processing, of language in the communication corresponding to an entity and one or more sentiments associated with the entity. The operation further may include determining whether the entity is unambiguously identifiable. Upon determining that the entity is not unambiguously identifiable, the operation may include identifying the entity based upon Bayesian inference. According to an embodiment, determining whether the entity is unambiguously identifiable may include determining whether the entity is among a plurality of participants in the communication.',\n",
       " \"Intelligently splitting text in messages posted on social media website to be more readable and understandable for user A method, system and computer program product for improving readability and understandability in messages posted on a social media website. The messages posted on a social media website, such as the user's social networking feed, are scanned. The scanned messages are analyzed for topics, meaning and/or tenses using natural language processing. The text in the scanned messages are split into message segments based on topic, meaning, tenses, punctuation, custom identifiers, hashtags and/or @ symbols. These message segments are then grouped based on relatedness of the topics, meaning and/or tenses. The message segments are ordered in each group of message segments, such as based on timestamps. The ordered message segments are then displayed to the user. By displaying these message segments in separate groupings in a logical order, the user will be able to view the messages posted on the user's social media website in a more readable and understandable manner.\",\n",
       " 'Dynamic semantic analysis on free-text reviews to identify safety concerns Disclosed are various embodiments for identifying safety concerns by employing dynamic semantic analysis on natural language provided in free-text reviews of products. A computing environment may encode user interface data that causes an event listener to monitor a free-text description provided in a text field in a user interface. A semantic analysis may be performed on the free-text description in real-time as the free-text description is generated. Remedial actions may be performed based on the semantics identified in the free-text description or severity levels associated with identified safety concerns.',\n",
       " 'Knowledge-based editor with natural language interface A computer-implemented method for knowledge based ontology editing, is provided. The method receives a language instance to update a knowledge base, using a computer. The method semantically parses the language instance to detect an ontology for editing. The method maps one or more nodes for the ontology for editing based on an ontology database and the knowledge base. The method determines whether the mapped nodes are defined or undefined within the knowledge base. The method calculates a first confidence score based on a number of the defined and undefined mapped nodes. Furthermore, the method updates the knowledge base when the first confidence score meets a pre-defined threshold.',\n",
       " 'Abstraction of syntax in localization through pre-rendering A content management system (CMS) and a translation management system (TMS) can utilize content dimensions for content items to manage and translate the content items between languages. Machine and human translations of complex dynamic content can also be improved by pre-rendering the content to remove localization-related syntax prior to machine or human translation. Content items can also be scored as to their suitability for localization prior to translation, and translation can be skipped for content items that do not have a sufficiently high score. Semantic and natural language processing (NLP) techniques can also be utilized for content categorization and routing. Translations of content items can also be continuously refined and higher quality re-translated content can be provided in an automated fashion.',\n",
       " 'Question and answer system emulating people and clusters of blended people Embodiments are directed to an information processing system for generating answers in response to questions. The system includes a memory, a processor system communicatively coupled to the memory. The processor system is configured to store in the memory data of a corpus of a predetermined entity, and receive a question comprising a natural language format. The processor circuit is further configured to analyze the data of the corpus of the predetermined entity to derive an emulated answer to the question, wherein the emulated answer includes an emulation of an actual answer that would be provided by the predetermined entity.',\n",
       " 'Hybrid natural language processor Methods and a natural language processor for processing a natural language query are provided. The processor includes a classifier, a rule-based pre-processor, a rule-based post-processor, a named entity recognizer, and an output module. The method involves receiving a text representation of the natural language query, pre-processing the text representation, applying a classification statistical model to the text representation when pre-processing fails, applying a post-processing rule, and performing name entity recognition.',\n",
       " 'Systems and methods for expressive language, developmental disorder, and emotion assessment, and contextual feedback In some embodiments, a method that includes capturing sound in a natural language environment using at least one sound capture device that is located in the natural language environment. The method also can include analyzing a sound signal from the sound captured by the at least one sound capture device to determine at least one characteristic of the sound signal. The method additionally can include reporting metrics that quantify the at least one characteristic of the sound signal. The metrics of the at least one characteristic can include a quantity of words spoken by one or more first persons in the natural language environment. Other embodiments are provided.',\n",
       " \"Dynamic gazetteers for personalized entity recognition In speech processing systems personalization is added in the Natural Language Understanding (NLU) processor by incorporating external knowledge sources of user information to improve entity recognition performance of the speech processing system. Personalization in the NLU is effected by incorporating one or more dictionaries of entries, or gazetteers, with information personal to a respective user, that provide the user's information to permit disambiguation of semantic interpretation for input utterances to improve quality of speech processing results.\",\n",
       " 'Voice search assistant Systems and methods for assisting voice searches are provided. An example method commences with receiving a voice query from a user and transmitting the voice query to a plurality of natural language processing systems. The method may continue with receiving a plurality of search parameter sets generated by the plurality of natural language processing systems based on the voice query. The method may further include transmitting at least one of the plurality of search parameter sets to a plurality of information search systems. The method may continue with receiving a plurality of responses from the plurality of information search systems. The plurality of responses may be generated by the plurality of information search systems based on the at least one of the plurality of search parameter sets. The method may conclude with providing at least one response of the plurality of responses to the user.',\n",
       " \"System and method of prediction through the use of latent semantic indexing A predictive modeling method implemented on a computer for predicting patient outcomes and conditions from medical database records of a population of patients, and an optimization process of iterative variation of parameters of the method to achieve a best precision fit. Individual patient documents are created by concatenation of unstructured text fields from the patient's medical record, and these are processed using Natural Language Processing. A patient document corpus is built, and terms in the corpus are weighted and mapped to standard vocabularies. A term-by-document matrix is built and its dimensionality is reduced by Latent Semantic Indexing. Patient and term queries are combined and scored, producing a ranked list. The parameters of the model are iteratively optimized for an input list of patients with corresponding health score values.\",\n",
       " 'Identifying an entity associated with an online communication An approach is described for identifying an entity associated with a communication in an online environment. A method pertaining to such approach may include receiving a communication within the online environment. The communication may be received via a communications network. The communication may include a plurality of sequential messages. The method further may include facilitating parsing, via natural language processing, of language in the communication corresponding to an entity and one or more sentiments associated with the entity. The method further may include determining whether the entity is unambiguously identifiable. Upon determining that the entity is not unambiguously identifiable, the method may include identifying the entity based upon Bayesian inference. According to an embodiment, determining whether the entity is unambiguously identifiable may include determining whether the entity is among a plurality of participants in the communication.',\n",
       " 'Relation extraction using QandA Embodiments of the present invention disclose a method, a computer program product, and a computer system for extracting natural language relations between entities. A computer receives a configuration for associating one or more natural language questions with one or more entities and identifies the one or more entities annotated within a document. The computer answers the natural language questions associated with the identified one or more entities based on context surrounding the identified one or more entities. The computer may further transmit the natural language questions associated with the identified one or more entities and the surrounding context to a question and answer service, then receive answers to the natural language questions from the question and answer service. The computer may further determine whether the received answers correctly describe the relation between the identified one or more entities and other entities within the extracted surrounding context.',\n",
       " 'Integration of domain information into state transitions of a finite state transducer for natural language processing The invention relates to a system and method for integrating domain information into state transitions of a Finite State Transducer (FST) for natural language processing. A system may integrate semantic parsing and information retrieval from an information domain to generate an FST parser that represents the information domain. The FST parser may include a plurality of FST paths, at least one of which may be used to generate a meaning representation from a natural language input. As such, the system may perform domain-based semantic parsing of a natural language input, generating more robust meaning representations using domain information. The system may be applied to a wide range of natural language applications that use natural language input from a user such as, for example, natural language interfaces to computing systems, communication with robots in natural language, personalized digital assistants, question-answer query systems, and/or other natural language processing applications.',\n",
       " 'Social networking response management system A system and method for managing electronic social networking includes defining content from a first user for communication to other users on an electronic social networking system. Natural language processing (NLP) and analytic analysis are applied to the content to identify a workflow for accessing and responding to the content. The access and the response to the content are based on the workflow.',\n",
       " 'Social networking response management system A system and method for managing electronic social networking includes defining content from a first user for communication to other users on an electronic social networking system. Natural language processing (NLP) and analytic analysis are applied to the content to identify a workflow for accessing and responding to the content. The access and the response to the content are based on the workflow.',\n",
       " 'Underspecification of intents in a natural language processing system A natural language processing system has a hierarchy of user intents related to a domain of interest, the hierarchy having specific intents corresponding to leaf nodes of the hierarchy, and more general intents corresponding to ancestor nodes of the leaf nodes. The system also has a trained understanding model that can classify natural language utterances according to user intent. When the understanding model cannot determine with sufficient confidence that a natural language utterance corresponds to one of the specific intents, the natural language processing system traverses the hierarchy of intents to find a more general user intent that is related to the most applicable specific intent of the utterance and for which there is sufficient confidence. The general intent can then be used to prompt the user with questions applicable to the general intent to obtain the missing information needed for a specific intent.',\n",
       " 'Method and system for generating natural language training data Provided is a system, method and computer-readable medium for generating data that may be used to train models for a natural language processing application. A system architect creates a plurality of sentence patterns that include entity variables and initiates sentence generation. Each entity is associated with one or more entity data sources. A language generator accepts the sentence patterns as inputs, and references the various entity sources to create a plurality of generated sentences. The generated sentences may be associated with a particular class and therefore used to train one or more statistical classification models and entity extraction models for associated models. The sentence generated process may be initiated and controlled using a user interface displayable on a computing device, the user interface in communication with the language generator module.',\n",
       " 'Evaluating user responses based on bootstrapped knowledge acquisition from a limited knowledge domain Mechanisms for training a human user to perform an operation and provided. The mechanisms generate a domain specific knowledge base comprising a set of entities and corresponding domain specific attributes and expand the domain specific knowledge base to include values for the domain specific attributes through an automated bootstrap learning process that performs natural language processing and analysis of natural language content using a set of pre-condition annotated action terms, thereby generating an expanded domain specific knowledge base. The mechanisms evaluate an input from another device identifying an action associated with an entity in the set of entities, based on a retrieved domain specific attribute value and the retrieved pre-condition annotation from the expanded domain specific knowledge base. The mechanisms output a notification to a user computing device indicating whether the input is correct or incorrect to thereby train a user associated with the user computing device.',\n",
       " 'Automating natural language task/dialog authoring by leveraging existing content Systems and methods for augmenting existing CU system to be used with content, such as a website. The content may be parsed to determine on or more actions that may be performed by a user who uses the content. These actions may then be compared to tasks of CU systems to identify potential matches. When a match is found, the CU system may be updated to include information.',\n",
       " 'Dynamic function builder Systems and techniques are disclosed for dynamically generating functions. The systems and techniques may be utilized to access and display information from a data store accessible to a spreadsheet-based application or program over a network. A web service is also provided that interprets data requests received from the spreadsheet-based application or program in one format, such as a natural language format, and translates the requests into syntactically correct functions with parameters for automatic execution by the spreadsheet-based application or program.',\n",
       " 'Seed selection in corpora compaction for natural language processing A method, system, and computer program product for seed selection in corpora compaction for natural language processing are provided in the illustrative embodiments. A set of initial clusters is formed from a set of documents in a corpus for natural language processing, wherein a subset of documents belong to an initial cluster in the set of initial cluster. A subset of the initial clusters is merged to form a merged cluster. A set of keywords that is representative of the merged cluster is identified. An epicenter of the merged cluster is formed using the set of keywords, the epicenter forming a seed. A document that is a member of the merged cluster is ranked according to a relationship of a taxonomy of the document and the epicenter.',\n",
       " 'Machine learning image processing A machine learning image processing system performs natural language processing (NLP) and auto-tagging for an image matching process. The system facilitates an interactive process, e.g., through a mobile application, to obtain an image and supplemental user input from a user to execute an image search. The supplemental user input may be provided from a user as speech or text, and NLP is performed on the supplemental user input to determine user intent and additional search attributes for the image search. Using the user intent and the additional search attributes, the system performs image matching on stored images that are tagged with attributes through an auto-tagging process.',\n",
       " 'Updating natural language interfaces by processing usage data A third-party company may assist companies in providing natural language interfaces for their customers. To implement a natural language interface for a company, a configuration may be received that includes information, such as a list intents, seed messages for the intents, and hierarchical information of the intents. An intent classifier may be trained using the configuration, and the natural language interface may be deployed for use with customers. Usage data of the natural language classifier may be collected and used to improve the natural language interface. Messages corresponding to an intent may be clustered into clusters of similar messages, and a prototype message may be obtained for each cluster to provide a human understandable description of the cluster. The information about the clusters may be used to improve the natural language interface, such as by creating a new intent with a cluster or moving a cluster to a different intent.',\n",
       " 'Natural language question answering method and apparatus A natural language question answering method and apparatus belong to the field of information retrieval and processing. The method includes: acquiring a natural language question N; converting the natural language question N into a query semantic graph Qs, each edge in the query semantic graph Qs representing one semantic relation in the natural language question N; searching an RDF graph G for a subgraph matching the query semantic graph Qs; and obtaining an answer to the natural language question N according to the subgraph.',\n",
       " 'Method and system of text synthesis based on extracted information in the form of an RDF graph making use of templates Disclosed are system, method and computer program product for synthesis of natural-language text; receiving information objects; selecting among the received information objects information objects and an associated synthesis templates in a template library, each synthesis template including a template semantic-syntactic tree; generating for each selected information object a synthesis semantic-syntactic tree based on the template semantic-syntactic tree; and generating natural language text based on each generated synthesis semantic-syntactic tree.',\n",
       " 'Camera operable using natural language commands In general, techniques of this disclosure may enable a computing device to capture one or more images based on a natural language user input. The computing device, while operating in an image capture mode, receive an indication of a natural language user input associated with an image capture command. The computing device determines, based on the image capture command, a visual token to be included in one or more images to be captured by the camera. The computing device locates the visual token within an image preview output by the computing device while operating in the image capture mode. The computing device captures one or more images of the visual token.',\n",
       " 'Generating test data from samples using natural language processing and structure-based pattern determination A method may include receiving a plurality of samples that include textual content. The method may include extracting unit values, corresponding to structural units, from the plurality of samples. The structural units may identify characteristics of the plurality of samples to be used to identify pattern information. The pattern information may identify unit values that are shared between at least two samples of the plurality of samples. The method may include generating one or more structural representations based on the unit values. The one or more structural representations may identify the pattern information. The method may include generating one or more additional samples based on the one or more structural representations. The one or more additional samples may include at least one of the unit values, and may be generated based on the pattern information. The method may include outputting the one or more additional samples.',\n",
       " 'Efficient dialogue policy learning Efficient exploration of natural language conversations associated with dialogue policy learning may be performed using probabilistic distributions. Exploration may comprise identifying key terms associated with the received natural language input utilizing the structured representation. Identifying key terms may include converting raw text of the received natural language input into a structured representation. Exploration may also comprise mapping at least one of the key terms to an action to be performed by the computer system in response to receiving natural language input associated with the at least one key term. Mapping may then be performed using a probabilistic distribution. The action may then be performed by the computer system. A replay buffer may also be utilized by the computer system to track what has occurred in previous conversations. The replay buffer may then be pre-filled with one or more successful dialogues to jumpstart exploration.',\n",
       " 'Method and system to communicate between devices through natural language using instant messaging applications and interoperable public identifiers A system and method to communicate between devices through natural language using instant messaging applications and interoperable public identifiers where the method comprises the stages of receiving an instant messaging module from an instant messaging client, an instant message in natural language, with an interoperable public identifier, identifying said message as a message to be processed because said interoperable public identifier corresponds to the public identifier that uniquely identifies said instant messaging module, processing said instant message and resending said message to a natural language processing module, processing the content of said message in said natural language processing module to translate said content into at least one specific command for a target device and launch the execution of the at least said command in said target device.',\n",
       " 'Automatic natural language processing based data extraction A data-driven big data mining and reporting system automatically identifies which data attributes to report from a first data set using natural language processing. The identified data attributes to report from the first data set is used to automatically extract additional data attributes to report from additional data sets so that the identified data attributes to report from the first data set and the extracted data attributes to report from the additional data sets can be reported without input from the end user.',\n",
       " 'System and method for determining description-to-permission fidelity in mobile applications A system and method are described to automatically assess description-to-permission fidelity of applications. The system and method can employ techniques in natural language processing and a learning-based algorithm to relate description with permissions.',\n",
       " 'Providing virtual personal assistance with multiple VPA applications The activities of multiple virtual personal assistant (VPA) applications are coordinated. For example, different portions of a conversational natural language dialog involving a user and a computing device may be handled by different VPAs.',\n",
       " \"Natural human-computer interaction for virtual personal assistant systems Technologies for natural language interactions with virtual personal assistant systems include a computing device configured to capture audio input, distort the audio input to produce a number of distorted audio variations, and perform speech recognition on the audio input and the distorted audio variants. The computing device selects a result from a large number of potential speech recognition results based on contextual information. The computing device may measure a user's engagement level by using an eye tracking sensor to determine whether the user is visually focused on an avatar rendered by the virtual personal assistant. The avatar may be rendered in a disengaged state, a ready state, or an engaged state based on the user engagement level. The avatar may be rendered as semitransparent in the disengaged state, and the transparency may be reduced in the ready state or the engaged state. Other embodiments are described and claimed.\",\n",
       " 'Aspect-based sentiment analysis and report generation using machine learning methods Systems and methods for aspect-based sentiment analysis using machine learning methods. An example method comprises: receiving, by a computer system, a custom dictionary comprising a list of lexemes referencing at least one of: a target entity or an aspect associated with the target entity; performing, using the custom dictionary, a syntactico-semantic analysis of at least part of a natural language text to produce a plurality of syntactico-semantic structures representing the part of the natural language text; evaluating, using one or more text characteristics produced by the syntactico-semantic analysis, a classifier function to determine polarities associated with one or more aspect terms; and generating a report comprising the aspect terms and polarities of aspects referenced by the aspect terms.',\n",
       " 'Techniques to predictively respond to user requests using natural language processing Techniques to predictively respond to user requests using natural language processing are described. In one embodiment, an apparatus may comprise a client communication component operative to receive a user service request from a user client; an interaction processing component operative to submit the user service request to a memory-based natural language processing component; generate a series of user interaction exchanges with the user client based on output from the memory-based natural language processing component, wherein the series of user interaction exchanges are represented in a memory component of the memory-based natural language processing component; and receive one or more operator instructions for the performance of the user service request from the memory-based natural language processing component; and a user interface component operative to display the one or more operator instructions in an operator console. Other embodiments are described and claimed.',\n",
       " 'Systems and methods for contextual retrieval and contextual display of records Provided are systems and methods for the contextual retrieval and contextual display of records. A search query and/or search results may be contextually enhanced based on (i) natural language processing (NLP) models, (ii) user behavior, and/or (iii) relationships between various entities involved in a search, such as between users, records, and/or fields of expertise. Contextually enhanced search results may be delivered and displayed to a user on a user interface in a contextually relevant order.',\n",
       " 'Machine learning auto completion of fields Systems and methods for using a mathematical model based on historical natural language inputs to automatically complete form fields are disclosed. An incident report may be defined with a set of required parameter fields such as category, priority, assignment, and classification. Incident report submission forms may also have other free text input fields providing information about a problem in the natural vocabulary of the person reporting the problem. Automatic completion of these so-called parameter fields may be based on analysis of the natural language inputs and use of machine learning techniques to determine appropriate values for the parameter fields. The machine learning techniques may include parsing the natural language input to determine a mathematical representation and application of the mathematical representation to match historically similar input. Once matched the parameter values from the historically similar input may be used instead of generic default values.',\n",
       " 'Library of existing spoken dialog data for use in generating new natural language spoken dialog systems A machine-readable medium may include a group of reusable components for building a spoken dialog system. The reusable components may include a group of previously collected audible utterances. A machine-implemented method to build a library of reusable components for use in building a natural language spoken dialog system may include storing a dataset in a database. The dataset may include a group of reusable components for building a spoken dialog system. The reusable components may further include a group of previously collected audible utterances. A second method may include storing at least one set of data. Each one of the at least one set of data may include ones of the reusable components associated with audible data collected during a different collection phase.',\n",
       " 'Systems and methods for generating functional application designs A method and apparatus for generating functional application designs is described. The method may include receiving one or more natural language utterances corresponding to natural language design commands for editing an application being designed. The method may also include editing one or more components of the application being designed based on each of the natural language utterances. Furthermore, the method may include generating a functional instance of the application being designed.',\n",
       " 'Method and system for software application optimization using natural language-based queries A method for software application optimization using natural language-based queries. The method includes obtaining a user-provided query. The user-provided query includes a constraint to be used for an identification of an application element that matches the constraint, from a set of application elements of a software application. The user-provided query is a string that includes a human language sentence. The method further includes deriving a formalized query from the user-provided query by translating the user-provided query into a syntactic construct of segmented sentence elements and obtaining the application element that matches the constraint. Obtaining the application element that matches the constraint includes deriving a pattern representation of the user-provided query from the formalized query and identifying the application element that matches the pattern representation of the user-provided query from the plurality of application elements.',\n",
       " 'Answering natural language table queries through semantic table representation According to one exemplary embodiment, a method for finding an answer to a query from a table is provided. The method may include receiving the query and the table. The method may also include generating a hierarchical representation based on the received table, whereby the hierarchical representation comprises a primary tree and a secondary tree. The method may then include mapping the primary tree to the secondary tree. The method may further include generating a plurality of predicate triples in a semantic relationship form based on the primary tree and the secondary tree. The method may also include determining if a predicate triple within the plurality of predicate triples matches the query using query-side and table-side context and semantics. The method may then include adding the predicate triple within the plurality of predicate triples to a plurality of candidate answers based on determining that the predicate triple matches the query.',\n",
       " 'Systems and methods for customized data parsing and paraphrasing Methods and apparatus, including computer program products, implementing and using techniques for customized data parsing and paraphrasing. A communications module receives content from several resources. An analytics engine parses the content based on a user query for content. An artificial intelligence engine determines a confidence ranking for the parsed content and determines a set of prioritized parsed content from the parsed content, based on the confidence ranking for the parsed content. A natural language engine converts, using a natural language processing technique, the set of prioritized parsed content into a format for user interface. A user interface presents a summarized output including the converted set of prioritized parsed content based on information associated with the user query.',\n",
       " 'Transferring information across language understanding model domains Aspects of the present invention provide a technique to validate the transfer of intents or entities between existing natural language model domains (hereafter domain or NLU) using click logs, a knowledge graph, or both. At least two different types of transfers are possible. Intents from a first domain may be transferred to a second domain. Alternatively or additionally, entities from the second domain may be transferred to an existing intent in the first domain. Either way, additional intent/entity pairs can be generated and validated. Before the new intent/entity pair is added to a domain, aspects of the present invention validate that the intent or entity is transferable between domains. Validation techniques that are consistent with aspects of the invention can use a knowledge graph, search query click logs, or both to validate a transfer of intents or entities from one domain to another.',\n",
       " 'System and method for providing controlled environment resident status Disclosed herein are system, method, and computer program product embodiments for providing controlled environment resident statuses. In an embodiment, a resident status communication system communicates with non-resident communication devices via audio calls and/or textual messages to provide inmate statuses as well as information related to the operation and administration of a correctional facility. The resident status communication system receives requests for information from the non-resident communication devices, determines whether the non-resident is authorized to access the requested information, and provides the requested information in a natural language format to facilitate the user experience. The resident status communication system also allows law enforcement officials and/or correctional facility staff to maintain statuses related to inmates and selectively distribute this information to authorized non-residents.',\n",
       " 'Systems and methods for automated alerts An alert suggestion generator may automatically suggest alerts for a user based on user input. The user input may include natural language text and/or user actions that the suggestion generator can use to generate alerts that have a high likelihood of relevance, and therefore desirability, to the user. Each alert may have a trigger condition such as passage of time, measurement of a numeric metric, or other factors. Each alert may also have a notification setting defining how the user is to be notified. The alert suggestion generator may retrieve a user profile of the user to further determine what alerts would be most relevant to the user. The user may be queried to confirm the alerts, and the alerts may them be set. Partial alerts may be generated and then the user may be queried for the trigger condition and/or notification setting needed to complete the alerts.',\n",
       " 'Method and system for conveying an example in a natural language understanding application A method (300) and system (100) is provided to add the creation of examples at a developer level in the generation of Natural Language Understanding (NLU) models, tying the examples into a NLU sentence database (130), automatically validating (310) a correct outcome of using the examples, and automatically resolving (316) problems the user has using the examples. The method (300) can convey examples of what a caller can say to a Natural Language Understanding (NLU) application. The method includes entering at least one example associated with an existing routing destination, and ensuring an NLU model correctly interprets the example unambiguously for correctly routing a call to the routing destination. The method can include presenting the example sentence in a help message (126) within an NLU dialogue as an example of what a caller can say for connecting the caller to a desired routing destination. The method can also include presented a failure dialogue for displaying at least one example that failed to be properly interpreted to ensure that ambiguous or incorrect examples are not presented in a help message.',\n",
       " \"Electronic message composition support method and apparatus An electronic message composition support system, method and architecture is provided. Techniques including machine learning and natural language processing techniques are used to extend message composition capability and support and to provide feedback to a user regarding an error, condition, etc. detected in the user's message before the user sends the message, e.g., while the user is composing the message using a messaging application's user interface.\",\n",
       " 'Systems and methods for integrating external resources from third-party services Various embodiments concern communication platforms that can integrate electronic resources distributed amongst various sources by tagging metadata associated with each of the electronic resources, thereby making the electronic resources readily searchable from a messaging interface using a single search architecture. The messaging interface can be used by users to communicate with one another. In some embodiments, the communication platform performs a search based on characters as they are entered into the text field of the messaging interface. This search across various heterogeneous sources enables the communication platform to identify a reference to an electronic resource the sender of a message wishes to insert within the message. Recipients of the message may be able to access the electronic resource directly from the messaging interface. The communication platform can also perform natural language processing techniques such as speech act detection on messages and/or other textual resources to facilitate intelligent communication streamlining.',\n",
       " 'Rule generation in a data governance framework The invention relates to computer-implemented method for supplementing a data governance framework with one or more new data governance technical rules. The method comprises providing a plurality of expressions and a first mapping. The expressions assign natural language patterns to technical language patterns. The first mapping maps first terms to data sources. A rule generator receives a new natural language (NL) rule comprising one or more natural-language patterns and one or more first terms. The rule generator resolves the new NL rule into one or more new technical rules interpretable by a respective rule engine and stores the one or more technical rules in a rule repository.',\n",
       " 'Combining natural language and keyword search queries for personal content collections Providing incremental search suggestions as a user enters terms in a search query includes determining if a recently entered term is in a context-free dictionary of natural language phrases, generating natural language query search completion candidates corresponding to terms provided by the user in the search query if the recently entered term is in the context free dictionary, determining if the recently entered term contains a keyword hint if the recently entered term is not in the context free dictionary, generating keyword search completion candidates if the recently entered term is at least part of a keyword hint, scoring the candidates from a current iteration and any previous iterations from previously entered terms to provide a set of possible candidates, and ordering the possible candidates based on at least the scoring. Providing incremental search suggestions may also include building compound search queries that include natural language phrases and keywords.',\n",
       " 'Query selection method and system A system and method for query selection are provided. The method may include acquiring a natural language sentence, pre-processing to obtain a standard node sequence, constructing a node tree based on the relationship between an index node and other nodes, generating a data query command based on the node tree, querying data using the data query command, and filtering the results. The standard node sequence may include at least an index node and a condition node. The node tree may be used to characterize the index-condition combination. The system may include an acquisition unit, a pre-processing unit, a node tree construction unit, a translation unit, and a querying and filtering unit.',\n",
       " 'Context-based endpoint detection The present disclosure generally relates to context-based endpoint detection in user speech input. A method for identifying an endpoint of a spoken request by a user may include receiving user input of natural language speech including one or more words; identifying at least one context associated with the user input; generating a probability, based on the at least one context associated with the user input, that a location in the user input is an endpoint; determining whether the probability is greater than a threshold; and in accordance with a determination that the probability is greater than the threshold, identifying the location in the user input as the endpoint.',\n",
       " \"System with multiple simultaneous speech recognizers A speech recognition system interprets both spoken system commands as well as application commands. Users may speak commands to an open microphone of a computing device that may be interpreted by at least two speech recognizers operating simultaneously. The first speech recognizer interprets operating system commands and the second speech recognizer interprets application commands. The system commands may include at least opening and closing an application and the application commands may include at least a game command or navigation within a menu. A reserve word may be used to identify whether the command is for the operation system or application. A user's cadence may also indicate whether the speech is a global command or application command. A speech recognizer may include a natural language software component located in a remote computing device, such as in the so-called cloud.\",\n",
       " 'Electronic notebook system An electronic notebook system is described that comprises a housing, a computing device, wireless interfaces, antennas, sensors, a touch display configured to receive input via a stylus and/or human digit input, the stylus comprising a pressure and/or an inclination sensor, a microphone, camera, the notebook system configured to provide a user condition interface, receive a user selection of a first user condition, provide an interface configured to receive user details, receive audible user details via the microphone, convert the audible user details received via the microphone to text, perform natural language processing to identify text keywords utilizing sentence segmentation, part-of-speech tagging, paraphrase recognition, and/or co-reference resolution, identify a condition based at least in part on the identified one or more keywords, dynamically generate an alert based at least in part on the identified condition, wirelessly transmit the generated alert to one or more destinations via at least a first wireless interface and antenna.',\n",
       " 'Generating and executing query language statements from natural language Techniques for generating query language statements for a document repository are described herein. An example method includes detecting a search query corresponding to a document repository and generating a modified search query by adding atomic tags to the search query, the atomic tags being based on prior knowledge obtained by static analysis of the document repository and semantic rules. The method also includes generating enriched tags based on combinations of the atomic tags and any previously identified enriched tags and generating a first set of conditions based on combinations of the atomic tags and the generated enriched tags and generating a second set of conditions based on free-text conditions. The method also includes generating the query language statements based on the first set of conditions and the second set of conditions and displaying a plurality of documents from the document repository that satisfy the query language statements.',\n",
       " 'Natural language processing based monitoring and resolution of open technical issues Aspects include a method, a system and a computer program product. The method includes identifying, on an electronic platform providing for an exchange of messages among multiple participants, at least one open issue to be resolved. Data is collected from the exchanged messages to determine a participation interaction parameter and a solution quality parameter associated with at least one open issue. The participation interaction parameter includes an accountability dynamic factor and collaboration dynamic factor and the solution quality parameter includes a velocity factor, a dormancy factor, and an extinction factor. When a sum of the participation interaction parameter and the solution quality parameter is below a threshold value, at least one open issue participant is invited to the electronic platform. It is also determined when the at least one open issue becomes a closed issue.',\n",
       " 'Translation of verbal directions into a list of maneuvers Natural language directions are received and a set of maneuver/context pairs are generated based upon the natural language directions. The set of maneuver/context pairs are provided to a routing engine to obtain route information based upon the set of maneuver/context pairs. The route information is provided to an output system for surfacing to a user.',\n",
       " 'Diagnosing autism spectrum disorder using natural language processing Embodiments herein include a natural language computing system that provides a diagnosis for a participant in the conversation which indicates the likelihood that the participant exhibited a symptom of autism. To provide the diagnosis, the computing system includes a diagnosis system that performs a training process to generate a machine learning model which is then used to evaluate a textual representation of the conversation. For example, the diagnosis system may receive one or more examples of baseline conversations that exhibit symptoms of autisms and those that do not. The diagnosis system may annotate and the baseline conversations and identify features that are used to identify the symptoms of autism. The system generates a machine learning model that weights the features according to whether the identified features are, or are not, an indicator of autism.',\n",
       " 'Extracting veiled meaning in natural language content Mechanisms for identifying hidden meaning in a portion of natural language content are provided. A primary portion of natural language content is received and a secondary portion of natural language content is identified that references the natural language content. The secondary portion of natural language content is analyzed to identify indications of meaning directed to elements of the primary portion of natural language content. A probabilistic model is generated based on the secondary portion of natural language content modeling a probability of hidden meaning in the primary portion of natural language content. A hidden meaning statement data structure is generated for the primary portion of natural language content based on the probabilistic model.',\n",
       " 'Interactive reformulation of speech queries Methods and systems are provided for providing alternative query suggestions. For example, a spoken natural language expression may be received and converted to a textual query by a speech recognition component. The spoken natural language expression may include one or more words, terms, and/or phrases. A phonetically confusable segment of the textual query may be identified by a classifier component. The classifier component may determine at least one alternative query based on identifying at least the phonetically confusable segment of the textual query. The classifier may further determine whether to suggest the at least one alternative query based on whether the at least one alternative query is sensical and/or useful. When it is determined to suggest the at least one alternative query, the at least one alternative query may be provided to and displayed on a user interface display.',\n",
       " 'Automated curation of documents in a corpus for a cognitive computing system A selected document from corpus of a cognitive computing system is processed according to its association with a category of documents already contained within the corpus, such as a topical category. Then, the cognitive computing system is engaged automatically to query one or more questions previously-associated with the category to discover discrepancies between the selected document and the other corpus documents. If a discrepancy is found, a confidence factor based upon extracted natural language entities and relationships is assigned to the discrepancy, and it is flagged and reported to a user for reconciliation.',\n",
       " 'Method and system for analyzing data using a query answering system Content data items in a first electronic file that correspond to entities in a database comprising categorized entities are identified. Modified content data items of a second electronic file are generated, the modified content data items indicating how the content data items are to be interpreted by a natural language query answering system. Information in the second electronic file indicating how the content data items are to be interpreted by the natural language query answering system are modified in response to user input. The second electronic file is used by the natural language query answering system to facilitate analysis of a natural language query regarding content in the first electronic file. Results of the analysis using the natural language query answering system are output.',\n",
       " 'System and method for matching resource capacity with resource needs Resources are required to satisfy various needs and wants of people, businesses, and machines. Resources come in the forms of time, talents, money, materials, energy, services, people, knowledge, communication, and other tangible and intangible assets. When both the capacities and the needs of multiple resources are stored in a way that allows for them to be connected together using computers, they can be efficiently and effectively matched. This matching creates shared value, which has potential academic, economic, societal and philanthropic benefits. Connected computer system(s) can query and match resources together in a way that is mutually beneficial. While a common lexicon is the simplest way to perform the matching, natural language processing, machine translation, or use of similar technologies may be optimal. Any method of collecting these inputs should be able to handle one or multiple capacities, and one or multiple needs.',\n",
       " 'Natural language processing based monitoring and resolution of open technical issues Aspects include a method, a system and a computer program product. The method includes identifying, on an electronic platform providing for an exchange of messages among multiple participants, at least one open issue to be resolved. Data is collected from the exchanged messages to determine a participation interaction parameter and a solution quality parameter associated with at least one open issue. The participation interaction parameter includes an accountability dynamic factor and collaboration dynamic factor and the solution quality parameter includes a velocity factor, a dormancy factor, and an extinction factor. When a sum of the participation interaction parameter and the solution quality parameter is below a threshold value, at least one open issue participant is invited to the electronic platform. It is also determined when the at least one open issue becomes a closed issue.',\n",
       " 'Active lab Various embodiments provide a tool, referred to herein as Active Lab that can be used to develop, debug, and maintain knowledge bases. These knowledge bases (KBs) can then engage various applications, technology, and communications protocols for the purpose of task automation, real time alerting, system integration, knowledge acquisition, and various forms of peer influence. In at least some embodiments, a KB is used as a virtual assistant that any real person can interact with using their own natural language. The KB can then respond and react however the user wants: answering questions, activating applications, or responding to actions on a web page.',\n",
       " 'Identifying user preferences and changing settings of a device based on natural language processing A method, a computer program product, and a computer system for identifying user preferences and changing settings of a device based on natural language processing. One or more programs running in background on the device capture an input of natural language from a user of the device, match the input of the natural language to a user frustration, map the user frustration to one or more solutions that make one or more changes of settings on the device, apply the one or more changes of settings to set user preference settings on the device, and store the user preference settings in a common store for the user.',\n",
       " 'Diagnosing autism spectrum disorder using natural language processing Embodiments herein include a natural language computing system that provides a diagnosis for a participant in the conversation which indicates the likelihood that the participant exhibited a symptom of autism. To provide the diagnosis, the computing system includes a diagnosis system that performs a training process to generate a machine learning model which is then used to evaluate a textual representation of the conversation. For example, the diagnosis system may receive one or more examples of baseline conversations that exhibit symptoms of autisms and those that do not. The diagnosis system may annotate and the baseline conversations and identify features that are used to identify the symptoms of autism. The system generates a machine learning model that weights the features according to whether the identified features are, or are not, an indicator of autism.',\n",
       " 'Cognitive reminder notification mechanisms for answers to questions A data processing system generates a result of processing a natural language query. A determination is made as to whether the natural language query or the result has a temporal characteristic. In response, a reminder notification data structure is generated having an associated scheduled reminder notification time for outputting a reminder notification of the result generated for the natural language query. The reminder notification data structure is stored in a data storage device and, at a later time from a time that the reminder notification data structure was stored in the data storage device, in response to the later time being equal to or later than the scheduled reminder notification time, a reminder notification is output to a client device associated with a user. The reminder notification specifies the result generated for the natural language query.',\n",
       " 'Cognitive reminder notification mechanisms for answers to questions A data processing system generates a result of processing a natural language query. A determination is made as to whether the natural language query or the result has a temporal characteristic. In response, a reminder notification data structure is generated having an associated scheduled reminder notification time for outputting a reminder notification of the result generated for the natural language query. The reminder notification data structure is stored in a data storage device and, at a later time from a time that the reminder notification data structure was stored in the data storage device, in response to the later time being equal to or later than the scheduled reminder notification time, a reminder notification is output to a client device associated with a user. The reminder notification specifies the result generated for the natural language query.',\n",
       " 'Exemplar-based natural language processing Systems and processes for exemplar-based natural language processing are provided. In one example process, a first text phrase can be received. It can be determined whether editing the first text phrase to match a second text phrase requires one or more of inserting, deleting, and substituting a word of the first text phrase. In response to determining that editing the first text phrase to match the second text phrase requires one or more of inserting, deleting, and substituting a word of the first text phrase, one or more of an insertion cost, a deletion cost, and a substitution cost can be determined. A semantic edit distance between the first text phrase and the second text phrase in a semantic space can be determined based on one or more of the insertion cost, the deletion cost, and the substitution cost.',\n",
       " 'Data analysis for automated coupling of simulation models A distributed computer system includes a distributed processor, a distributed memory, and a simulation engine (SE). The SE includes a simulation I/O coupler that links a first variable of a first simulation model I/O data structure to a second variable of a second simulation model I/O data structure. The SE includes a natural language processing system that extracts a first variable description associated with the first variable, determines similar character strings to the first variable description from an information corpus, and ranks the determined character strings based upon similarity to the first variable description. The SE links the first variable to the second variable if the rank of an equal character string to the second variable description is greater than a rank threshold. The SE may augment the simulation model I/O data structures by writing a value of the first variable to a value of the second variable, or visa versa.',\n",
       " 'Contextual validation of synonyms in otology driven natural language processing Embodiments described herein provide approaches for validating synonyms in ontology driven natural language processing. Specifically, an approach is provided for receiving a user input containing a token, structuring the user input into a semantic model comprising a set of classes each containing a set of related permutations of the token, designating the token as a synonym of one of the set of related permutations, annotating the token with a class from the set of classes corresponding to the one of the set of related permutations, and validating the annotation of the token by determining an accuracy of the designation of the token as a synonym of the one of the set of related permutations. In one embodiment, the accuracy is determined by quantifying a linear distance between the token and a contextual token also within the user input, and comparing the linear distance to a pre-specified linear distance limit.',\n",
       " 'Translating structured languages to natural language using domain-specific ontology Methods, systems, and computer program products for translating structured languages to natural language using domain-specific ontology are provided herein. A computer-implemented method includes determining similarities among multiple natural language query interpretations derived from an input query, determining differences among the multiple natural language query interpretations, and generating natural language descriptions of each of the multiple natural language query interpretations based on analysis of the determined similarities, the determined differences, and the input query. The method also includes producing, for each of the natural language query interpretations, a natural language string that represents one or more unambiguous interpretations of the input query, wherein the producing comprises consolidating the generated natural language descriptions. Further, the method includes outputting each of the produced natural language strings to a user.',\n",
       " 'Converting data into natural language form Converting technical data from field oriented electronic data sources into natural language form is disclosed. An approach includes obtaining document data from an input document, wherein the document data is in a non-natural language form. The approach includes determining a data type of the document data from one of a plurality of data types defined in a detection and conversion database. The approach includes translating the document data to a natural language form based on the determined data type. The approach additionally includes outputting the translated document data in natural language form to an output data stream.',\n",
       " \"Natural language interpretation of hierarchical data A computer-implemented method includes receiving a search label and accessing a hierarchical data source comprising a plurality of nodes. One node may be a context node. The method further includes determining a similarity score between the search label and a node label of each node, determining a contextual score between the context node and each node, combining, for each node, the similarity score with the contextual score to yield a combined score, and returning a result. The result may be based on ordering the plurality of nodes according to each node's combined score. A corresponding computer program product and computer system are also disclosed.\",\n",
       " 'Systems and methods for identifying a meaning of an ambiguous term in a natural language query Methods and systems for identifying a meaning of an ambiguous term in a natural language query. The media guidance application isolates first and second terms from a query received from a user and identifies, in a knowledge graph, first and second pluralities of candidate components associated with the first and second terms. The first and second terms each having multiple candidate components indicates the first and second terms have ambiguous meanings. The media guidance application matches each candidate component of the first and second pluralities of candidate components to form a plurality of pairs and determines strength of association for each pair in the plurality of pairs. The media guidance application filters the plurality of pairs by strength of association for each pair and determines a plurality of possible meanings based on the filtered plurality of pairs. The media guidance application selects a meaning from the plurality of possible meanings.',\n",
       " 'Generating and executing query language statements from natural language Techniques for generating query language statements for a document repository are described herein. An example method includes detecting a search query corresponding to a document repository and generating a modified search query by adding atomic tags to the search query, the atomic tags being based on prior knowledge obtained by static analysis of the document repository and semantic rules. The method also includes generating enriched tags based on combinations of the atomic tags and any previously identified enriched tags and generating a first set of conditions based on combinations of the atomic tags and the generated enriched tags and generating a second set of conditions based on free-text conditions. The method also includes generating the query language statements based on the first set of conditions and the second set of conditions and displaying a plurality of documents from the document repository that satisfy the query language statements.',\n",
       " 'Coefficients attribution for different objects based on natural language processing In one embodiment, a method includes receiving, from a client device that corresponds to a user of an online social network, an input that comprises free-form text; determining, through application of natural-language processing of the free-form text, an affinity declaration for an object associated with the online social network; determining an affinity coefficient between respective user and the object; adjusting the determined affinity coefficient based on social-networking information of the user, wherein the social-networking information reinforces or reduces the determined affinity coefficient; and upon determining that the determined affinity coefficient is above a threshold coefficient, creating or modifying an edge connection in a social graph between a user node corresponding to the user and a concept node corresponding to the object.',\n",
       " 'System and method for analogy detection and analysis in a natural language question and answering system A system, method, and a computer program product are provided for evaluating an analogical pattern by applying natural language processing to an information source to identify analogical pattern terms in a first analogical pattern, applying deep analysis to refine the analogical pattern terms based on semantic analysis to form metadata for the first analogical pattern, generating interpretations of different combinations of the first analogical pattern terms and the metadata, and then scoring each interpretation for each of the different combinations to select a first interpretation exceeding a predetermined threshold for interpretation of the analogical pattern, thereby evaluating the first analogical pattern.',\n",
       " 'Corpus quality analysis A mechanism is provided in a data processing system for corpus quality analysis. The mechanism applies at least one filter to a candidate corpus to determine a degree to which the candidate corpus supplements existing corpora for performing a natural language processing (NLP) operation. Responsive to a determination to add the candidate corpus to the existing corpora based on a result of applying the at least one filter, the mechanism adds the candidate corpus to the existing corpora to form modified corpora. The mechanism performs the NLP operation using the modified corpora.',\n",
       " 'Electronic device, method and training method for natural language processing Provided are an electronic device, a method and a training method for natural language processing. The electronic device for natural language processing includes a processor configured to: for each of words obtained by segmenting a sentence in a training data set, obtain an attention parameter representing correlation between the word and each of one or more words of other words in the sentence, where each of the words is represented by a real vector; and train, based on each of the words in the sentence, information on the attention parameter acquired for the word and label information of the sentence in the training data set, a neural network for sentence classification.',\n",
       " \"Systems and methods for adaptive proper name entity recognition and understanding Various embodiments contemplate systems and methods for performing automatic speech recognition (ASR) and natural language understanding (NLU) that enable high accuracy recognition and understanding of freely spoken utterances which may contain proper names and similar entities. The proper name entities may contain or be comprised wholly of words that are not present in the vocabularies of these systems as normally constituted. Recognition of the other words in the utterances in question, e.g. words that are not part of the proper name entities, may occur at regular, high recognition accuracy. Various embodiments provide as output not only accurately transcribed running text of the complete utterance, but also a symbolic representation of the meaning of the input, including appropriate symbolic representations of proper name entities, adequate to allow a computer system to respond appropriately to the spoken request without further analysis of the user's input.\",\n",
       " 'Maintaining context for voice processes A system capable of generating and storing progress data associated with third party services. A voice enabled device may receive voice commands and the system may perform natural language understanding (NLU) to interpret the voice commands, determine a corresponding process and send instructions to a third party server associated with the process. In order to resume the process after the process is interrupted, the system may save and/or cause the third party server to save progress data and/or a checkpoint corresponding to a status of the process at the time that the process is interrupted. The system may use the progress data to resume the process at a later point based on the status. In addition, the system may track processes associated with saved progress data/checkpoints and may interpret incoming voice commands based on the tracked processes.',\n",
       " 'Intelligent assistant for home automation This relates to systems and processes for using a virtual assistant to control electronic devices. In one example process, a user can speak an input in natural language form to a user device to control one or more electronic devices. The user device can transmit the user speech to a server to be converted into a textual representation. The server can identify the one or more electronic devices and appropriate commands to be performed by the one or more electronic devices based on the textual representation. The identified one or more devices and commands to be performed can be transmitted back to the user device, which can forward the commands to the appropriate one or more electronic devices for execution. In response to receiving the commands, the one or more electronic devices can perform the commands and transmit their current states to the user device.',\n",
       " 'Systems and methods for integrating external resources from third-party services Various embodiments concern communication platforms that can integrate electronic resources distributed amongst various sources by tagging metadata associated with each of the electronic resources, thereby making the electronic resources readily searchable from a messaging interface using a single search architecture. The messaging interface can be used by users to communicate with one another. In some embodiments, the communication platform performs a search based on characters as they are entered into the text field of the messaging interface. This search across various heterogeneous sources enables the communication platform to identify a reference to an electronic resource the sender of a message wishes to insert within the message. Recipients of the message may be able to access the electronic resource directly from the messaging interface. The communication platform can also perform natural language processing techniques such as speech act detection on messages and/or other textual resources to facilitate intelligent communication streamlining.',\n",
       " 'Systems and methods for integrating external resources from third-party services Various embodiments concern communication platforms that can integrate electronic resources distributed amongst various sources by tagging metadata associated with each of the electronic resources, thereby making the electronic resources readily searchable from a messaging interface using a single search architecture. The messaging interface can be used by users to communicate with one another. In some embodiments, the communication platform performs a search based on characters as they are entered into the text field of the messaging interface. This search across various heterogeneous sources enables the communication platform to identify a reference to an electronic resource the sender of a message wishes to insert within the message. Recipients of the message may be able to access the electronic resource directly from the messaging interface. The communication platform can also perform natural language processing techniques such as speech act detection on messages and/or other textual resources to facilitate intelligent communication streamlining.',\n",
       " 'Process control system using typical and adapter components Methods, systems, and non-transitory, computer-readable medium are disclosed to enable a user to configure a process control system. A graphical programming user interface is described for generating coded native control components instantiated from typical and adapter components selected from a library of templates including respective control functions and associated logical expressions. In various embodiments, typical components represent a common core control process or function that is used among one or more other plant equipment devices in the process control system. In addition, various embodiments of the adapter components include one or more parameters that may be changed by a user in conjunction with the logical expressions and/or defined in terms of natural language expressions. As a result, the typical component and the adapter component are instantiated to provide a native control component that provides functionality with respect to one or more control loops within a process control system.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = df.patent_title_abstract.tolist()\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 80 20 100\n"
     ]
    }
   ],
   "source": [
    "# partition data\n",
    "len(text_data)\n",
    "text_train = text_data[:round(len(text_data)*.8)]\n",
    "text_test = text_data[round(len(text_data)*.8):]\n",
    "print(len(text_data), len(text_train), len(text_test), len(text_train)+len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download stop words from nltk and language package from spacy\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x1a31d8e748>),\n",
      " ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x1a33418c48>),\n",
      " ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x1a33418ca8>)]\n"
     ]
    }
   ],
   "source": [
    "# construct pipeline using Spacy Language object and associated pipeline/components\n",
    "nlp = spacy.load(\"en\")\n",
    "pprint(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/runpy.py:193: DeprecationWarning: [W016] The keyword argument `n_threads` on the is now deprecated, as the v2.x models cannot release the global interpreter lock. Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-89dcf039b871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Remove common words from a stopword list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Add named entities, but only if they are a compound of more than word.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-89dcf039b871>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Remove common words from a stopword list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Add named entities, but only if they are a compound of more than word.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "processed_docs = []   \n",
    "\n",
    "# process patent documents in pipeline\n",
    "for doc in nlp.pipe(text_train, n_threads=4, batch_size=100):\n",
    "   \n",
    "    ents = doc.ents  # Named entities.\n",
    "\n",
    "    # Keep only words (no numbers, no punctuation).\n",
    "    # Lemmatize tokens, remove punctuation and remove stopwords.\n",
    "    doc = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    # Remove common words from a stopword list.\n",
    "    doc = [token for token in doc if token not in stop_words]\n",
    "\n",
    "    # Add named entities, but only if they are a compound of more than word.\n",
    "    doc.extend([str(entity) for entity in ents if len(entity) > 1])\n",
    "    \n",
    "    processed_docs.append(doc)\n",
    "\n",
    "processed_docs[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set([w.label_ for w in doc.ents]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels: \n",
    "    entities = [cleanup(e.string, lower=False) for e in document.ents if label==e.label_] \n",
    "    entities = list(set(entities)) \n",
    "    print(label,entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-e7ce071650ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpre_processed_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Process document using Spacy NLP pipeline.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m  \u001b[0;31m# Named entities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "pre_processed_docs = []\n",
    "for doc in nlp.pipe(docs, n_threads=4, batch_size=100):\n",
    "    # Process document using Spacy NLP pipeline.\n",
    "    \n",
    "    ents = doc.ents  # Named entities.\n",
    "\n",
    "    # Keep only words (no numbers, no punctuation).\n",
    "    # Lemmatize tokens, remove punctuation and remove stopwords.\n",
    "    doc = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    # Remove common words from a stopword list.\n",
    "    #doc = [token for token in doc if token not in STOPWORDS]\n",
    "\n",
    "    # Add named entities, but only if they are a compound of more than word.\n",
    "    doc.extend([str(entity) for entity in ents if len(entity) > 1])\n",
    "    \n",
    "    pre_processed_docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize documents\n",
    "\n",
    "def tokenize_docs(docs):\n",
    "    tokenized_docs = []\n",
    "    for doc in docs:\n",
    "        tokenized_docs.append(word_tokenize(doc))\n",
    "    return tokenized_docs\n",
    "\n",
    "tokenized_docs = tokenize_docs(text_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean punctuation\n",
    "def clean_docs(tokenized_docs):\n",
    "    clean_docs = []\n",
    "    for doc in tokenized_docs:\n",
    "       clean_docs.append([word for word in doc if word.isalpha()])  \n",
    "    return clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = clean_docs(tokenized_docs)\n",
    "cleaned_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "def lower_words(docs):\n",
    "    lowered_words = []\n",
    "    for doc in docs:\n",
    "        lowered_words.append([word.lower() for word in doc])\n",
    "    return lowered_words\n",
    "\n",
    "lowered_data = lower_words(cleaned_data)\n",
    "lowered_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(docs):\n",
    "    filtered_docs = []\n",
    "    for doc in docs:\n",
    "       filtered_docs.append([word for word in doc if word not in stop_words])\n",
    "    return filtered_docs\n",
    "\n",
    "# remove stopwords\n",
    "filtered_data = filter_stopwords(lowered_data)\n",
    "filtered_data\n",
    "# TODO (Lee) - resolve un-lowered stopwords \"A\" and \"An\", 'By', 'The'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create corpus and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-0d5e7a6b7838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# using spacy pipeline components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# build dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mid_to_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# build corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_docs' is not defined"
     ]
    }
   ],
   "source": [
    "# using spacy pipeline components\n",
    "# build dictionary\n",
    "id_to_word = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# build corpus\n",
    "texts = processed_docs\n",
    "\n",
    "# apply term document frequency\n",
    "# converts documents in corpus to bag-of-words format, a list of (token_id, token_count) tuples\n",
    "corpus = [id_to_word.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # build dictionary\n",
    "id_to_word = corpora.Dictionary(filtered_data)\n",
    "\n",
    "# build corpus\n",
    "texts = filtered_data\n",
    "\n",
    "# apply term document frequency\n",
    "# converts documents in corpus to bag-of-words format, a list of (token_id, token_count) tuples\n",
    "corpus = [id_to_word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view formatted corpus (term-doc-frequency)\n",
    "[[(id_to_word[id], freq) for id, freq in text] for text in corpus][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - deprecation warnings\n",
    "# construct LDA model\n",
    "model_lda = LdaModel(corpus=corpus,\n",
    "                     id2word=id_to_word,\n",
    "                     num_topics=25, \n",
    "                     random_state=100,\n",
    "                     update_every=1,\n",
    "                     chunksize=100,\n",
    "                     passes=10,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print keywords in n topics\n",
    "pprint(model_lda.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 10 keywords that comprise topic with index of 0\n",
    "pprint(model_lda.print_topic(24))\n",
    "# the most import keywords, and the respective weight, that form topic 0 are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 10 keywords that comprise topic with index of 1\n",
    "pprint(model_lda.print_topic(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - infer topic from keywords?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate - model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate perplexity metrics\n",
    "perplexity = model_lda.log_perplexity(corpus)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - confirm that filtered_data is indeed the correct dataset to pass to texts param\n",
    "# calculate coherence metric\n",
    "coherence = CoherenceModel(model=model_lda, texts=processed_docs, dictionary=id_to_word, coherence='c_v')\n",
    "coherence_1 = coherence.get_coherence()\n",
    "coherence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - confirm that filtered_data is indeed the correct dataset to pass to texts param\n",
    "# calculate coherence metric\n",
    "coherence = CoherenceModel(model=model_lda, texts=filtered_docs, dictionary=id_to_word, coherence='c_v')\n",
    "coherence_1 = coherence.get_coherence()\n",
    "coherence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coherence metric or each of the n topicss\n",
    "coherence_1 = coherence.get_coherence_per_topic()\n",
    "coherence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore topics\n",
    "pyLDAvis.enable_notebook()\n",
    "viz_topics_1 = pyLDAvis.gensim.prepare(model_lda, corpus, id_to_word)\n",
    "viz_topics_1\n",
    "# TODO (Lee) - salient vs relevant terms in pyLDA ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2-  Mallet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download Mallet topic model\n",
    "# !wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "# update this path\n",
    "path_mallet = 'data/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = gensim.models.wrappers.LdaMallet(path_mallet, corpus=corpus, num_topics=25, id2word=id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics\n",
    "pprint(model_2.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coherence metric\n",
    "coherence_model_2 = CoherenceModel(model=model_2, texts=data, dictionary=id_to_word, coherence='c_v')\n",
    "coherence_model_2 = coherence_model_2.get_coherence()\n",
    "coherence_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee)\n",
    "# def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "#     \"\"\"\n",
    "#     Compute c_v coherence for various number of topics\n",
    "\n",
    "#     Parameters:\n",
    "#     ----------\n",
    "#     dictionary : Gensim dictionary\n",
    "#     corpus : Gensim corpus\n",
    "#     texts : List of input texts\n",
    "#     limit : Max num of topics\n",
    "\n",
    "#     Returns:\n",
    "#     -------\n",
    "#     model_list : List of LDA topic models\n",
    "#     coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "#     \"\"\"\n",
    "#     coherence_values = []\n",
    "#     model_list = []\n",
    "#     for num_topics in range(start, limit, step):\n",
    "#         model = gensim.models.wrappers.LdaMallet(path_mallet, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "#         model_list.append(model)\n",
    "#         coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "#         coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "#     return model_list, coherence_values\n",
    "\n",
    "# model_list, coherence_values = compute_coherence_values(dictionary=id_to_word, corpus=corpus, texts=data, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Author topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct inventor-to-doc mapping as df from nested inventors column in json api response\n",
    "df_inventors = json_normalize(results['patents'], record_path=['inventors'], meta=['patent_number', 'patent_date'])\n",
    "df_inventors = df_inventors[['inventor_id', 'patent_number', 'patent_date']]\n",
    "df_inventors.sort_values(by=['patent_date'])\n",
    "df_inventors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - resolve workaround\n",
    "df_idx = df\n",
    "df_idx['idx'] = df.index\n",
    "df_idx\n",
    "df_idx_1 = df_idx[['patent_number', 'idx', 'inventors']]\n",
    "df_idx_2 = df_idx_1.set_index('patent_number')\n",
    "df_idx_2.pop('inventors')\n",
    "df_idx_2\n",
    "df_pat_idx = df_idx_2.T.to_dict('records')\n",
    "for i in df_pat_idx:\n",
    "    df_pat_idx = dict(i)\n",
    "df_pat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pat_idx = df_idx_2.T.to_dict('records')\n",
    "for i in df_pat_idx:\n",
    "    df_pat_idx = dict(i)\n",
    "df_pat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv_test = json_normalize(results['patents'], record_path=['inventors'], meta=['patent_number', 'patent_date'])\n",
    "df_inv_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idx_pat_inv_map = df[['patent_number', 'inventors']]\n",
    "df_idx_pat_inv_map.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - find out how to get list of patents_view_field names from API - I did it accidentally but need to replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.patent_title_abstract[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inventors.set_index('inventor_id').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in pat2inv.items():\n",
    "#     name_dict[new_key] = name_dict.pop(k)\n",
    "#     time.sleep(4)\n",
    "\n",
    "# pprint.pprint(name_dict)\n",
    "\n",
    "# d = {'x':1, 'y':2, 'z':3}\n",
    "# d1 = {'x':'a', 'y':'b', 'z':'c'}\n",
    "\n",
    "# dict((d1[key], value) for (key, value) in d.items())\n",
    "# {'a': 1, 'b': 2, 'c': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patdf2inv = dict((df_pat_idx[key], value) for (key, value) in pat2inv.items())\n",
    "patdf2inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat2inv = {k: list(v) for k,v in df_inventors.groupby(\"patent_number\")[\"inventor_id\"]}\n",
    "pat2inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx_pat_map = df.patent_number.to_dict()\n",
    "idx_pat_map = {str(key): value for key, value in idx_pat_map.items()}\n",
    "idx_pat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct author-topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct author-topic model\n",
    "model_at = AuthorTopicModel(corpus=corpus,\n",
    "                         doc2author=patdf2inv,\n",
    "                         id2word=id_to_word, \n",
    "                         num_topics=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct vectors for authors\n",
    "author_vecs = [model_at.get_author_topics(author) for author in model_at.id2author.values()]\n",
    "author_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the topic distribution for an author using use model[name] syntax\n",
    "# each topic has a probability of being expressed given the particular author, but only the ones above a certain threshold are shown.\n",
    "\n",
    "model_at['7788103-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_author(name):\n",
    "#     print('\\n%s' % name)\n",
    "#     print('Docs:', model.author2doc[name])\n",
    "#     print('Topics:')\n",
    "#     pprint([(topic_labels[topic[0]], topic[1]) for topic in model[name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate per-word bound, which is a measure of the model's predictive performance (reconstruction error?)\n",
    "\n",
    "build doc2author dictionary\n",
    "\n",
    "doc2author = atmodel.construct_doc2author(model.corpus, model.author2doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import atmodel\n",
    "doc2author = atmodel.construct_doc2author(model.corpus, model.author2doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.atmodel.construct_author2doc(doc2author)\n",
    "# construct mapping from author IDs to document IDs.\n",
    "\n",
    "Parameters:\tdoc2author (dict of (int, list of str))  Mapping of document id to authors.\n",
    "Returns:\tMapping of authors to document ids.\n",
    "Return type:\tdict of (str, list of int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.atmodel.construct_doc2author(corpus, author2doc)\n",
    "construct mapping from document IDs to author IDs\n",
    "\n",
    "Parameters:\t\n",
    "corpus (iterable of list of (int, float))  Corpus in BoW format.\n",
    "author2doc (dict of (str, list of int))  Mapping of authors to documents.\n",
    "Returns:\t\n",
    "Document to Author mapping.\n",
    "\n",
    "Return type:\t\n",
    "dict of (int, list of str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import full dataset from PatentsView API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to use\n",
    "\n",
    "# def get_patents_by_month(begin_date,end_date, pats_per_page):\n",
    "#     \"\"\" requests patent data from PatentsView API by date range\"\"\"\n",
    "#     endpoint_url = 'http://www.patentsview.org/api/patents/query'\n",
    "#     page_counter=1\n",
    "#     data = []\n",
    "#     results = {}\n",
    "#     count=1\n",
    "    \n",
    "#     for i in range(round(100000/pats_per_page)): # TODO (Lee) - replace with datetime for begin_date to end_date\n",
    "        \n",
    "#         if count ==0:\n",
    "#             print(\"error/complete\")\n",
    "#             break\n",
    "            \n",
    "#         elif count > 0:     \n",
    "#             # build query\n",
    "#             query = {\"_and\":[{\"_gte\":{\"patent_date\":\"2017-01-01\"}},{\"_lte\":{\"patent_date\":\"2017-01-31\"}}]}\n",
    "#             fields=pat_fields\n",
    "#             options={\"page\": page_counter, \"per_page\":pats_per_page}\n",
    "#             sort=[{\"patent_date\":\"desc\"}]\n",
    "#             params={'q': json.dumps(query),\n",
    "#                     'f': json.dumps(fields),\n",
    "#                     'o': json.dumps(options),\n",
    "#                     's': json.dumps(sort)\n",
    "#                         }\n",
    "    \n",
    "#             # request and results\n",
    "#             response = requests.get(endpoint_url, params=params)\n",
    "#             status = response.status_code\n",
    "#             print(\"status:\", status,';',\"page_counter:\",page_counter, \";\", \"iteration:\",i)\n",
    "#             results = response.json()\n",
    "#             count = results.get(\"count\")\n",
    "#             total_pats = results.get(\"total_patent_count\")\n",
    "#             print(\"patents on current page:\",count,';', \"total patents:\",total_pats)\n",
    "#             data.extend(results)\n",
    "#             page_counter+=1\n",
    "        \n",
    "#     return data\n",
    "#             # TODO (Lee) results =  json.loads(response.content)\n",
    "#             # TODO (Lee) places.extend(results['results'])\n",
    "#             # TODO (Lee) time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPC fields for block 1 of query:\n",
    "Y10S-706 OR \n",
    "G06N-003 OR \n",
    "G06N-005/003:G06N-005/027 OR \n",
    "G06N- 007/005:G06N-007/06 OR \n",
    "G06N-099/005 OR\n",
    "G06T2207/20081 OR\n",
    "G06T2207/20084 OR\n",
    "G06T-003/4046 OR\n",
    "G06T-009/002 OR\n",
    "G06F-017/16 OR\n",
    "G05B-013/027 OR\n",
    "G05B- 013/0275 OR\n",
    "G05B-013/028 OR\n",
    "G05B-013/0285 OR\n",
    "G05B-013/029 OR\n",
    "G05B-013/0295 OR\n",
    "G05B-2219/33002 OR\n",
    "G05D-001/0088 OR\n",
    "G06K-009 OR\n",
    "G10L-015 OR\n",
    "G10L-017 OR\n",
    "G06F-017/27:G06F-017/2795 OR\n",
    "G06F-017/28:G06F-017/289 OR\n",
    "G06F-017/30029:G06F- 017/30035 OR\n",
    "G06F-017/30247:G06F-017/30262 OR \n",
    "G06F-017/30401 OR\n",
    "G06F-017/3043 OR \n",
    "G06F-017/30522:G06F-017/3053 OR \n",
    "G06F-017/30654 OR \n",
    "G06F-017/30663 OR\n",
    "G06F-017/30666 OR \n",
    "G06F-017/30669 OR\n",
    "G06F-017/30672 OR \n",
    "G06F-017/30684 OR\n",
    "G06F-017/30687 OR \n",
    "G06F-017/3069 OR \n",
    "G06F-017/30702 OR\n",
    "G06F-017/30705:G06F- 017/30713 OR\n",
    "G06F-017/30731:G06F-017/30737 OR\n",
    "G06F-017/30743:G06F-017/30746 OR \n",
    "G06F-017/30784:G06F-017/30814 OR\n",
    "G06F-019/24 OR G06F-019/707 OR\n",
    "G01R- 031/2846:G01R-031/2848 OR\n",
    "G01N-2201/1296 OR\n",
    "G01N-029/4481 OR\n",
    "G01N-033/0034 ORG01R-031/3651ORG01S-007/417ORG06N-003/004:G06N-003/008 ORG06F- 011/1476 OR \n",
    "G06F-011/2257 OR \n",
    "G06F-011/2263 OR \n",
    "G06F-015/18 OR\n",
    "G06F-2207/4824 OR\n",
    "G06K-007/1482 OR\n",
    "G06N-007/046 OR\n",
    "G11B-020/10518 OR\n",
    "G10H-2250/151 OR\n",
    "G10H-2250/311 OR\n",
    "G10K-2210/3024 OR\n",
    "H01J-2237/30427 OR\n",
    "H01M-008/04992 OR\n",
    "H02H-001/0092 OR\n",
    "H02P-021/0014 OR\n",
    "H02P-023/0018 OR\n",
    "H03H-2017/0208 OR\n",
    "H03H- 2222/04 OR\n",
    "H04L-2012/5686 OR\n",
    "H04L-2025/03464 OR\n",
    "H04L-2025/03554 OR\n",
    "H04L- 025/0254 OR\n",
    "H04L-025/03165 OR\n",
    "H04L-041/16 OR\n",
    "H04L-045/08 OR\n",
    "H04N- 021/4662:H04N-021/4666 OR\n",
    "H04Q-2213/054 \n",
    "OR H04Q-2213/13343 OR\n",
    "H04Q-2213/343 OR\n",
    "H04R-025/507 OR\n",
    "G08B-029/186 OR\n",
    "B60G-2600/1876 OR\n",
    "B60G-2600/1878 OR\n",
    "B60G-2600/1879 OR\n",
    "B64G-2001/247 OR\n",
    "E21B-2041/0028 OR\n",
    "B23K-031/006 OR\n",
    "B29C- 2945/76979 OR\n",
    "B29C-066/965 OR\n",
    "B25J-009/161 OR\n",
    "A61B-005/7264:A61B-005/7267 OR\n",
    "Y10S-128/924 OR\n",
    "Y10S-128/925 OR\n",
    "F02D-041/1405 OR\n",
    "F03D-007/046 OR\n",
    "F05B- 2270/707 OR\n",
    "F05B-2270/709 OR\n",
    "F16H-2061/0081 OR\n",
    "F16H-2061/0084 OR\n",
    "B60W-030/06 OR\n",
    "B60W-030/10:B60W-030/12 OR\n",
    "B60W-030/14:B60W-030/17 OR\n",
    "B62D-015/0285 OR\n",
    "G06T-2207/30248:G06T-2207/30268 OR\n",
    "G06T-2207/30236 OR G05D-001 OR\n",
    "A61B- 005/7267 OR\n",
    "F05D-2270/709 OR\n",
    "G06T-2207/20084 OR\n",
    "G10K-2210/3038 OR\n",
    "G10L-025/30 OR\n",
    "H04N-021/4666 OR\n",
    "A63F-013/67 OR\n",
    "G06F-017/2282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import data from bulk download\n",
    "\n",
    "# uncomment to download TSV files containing detailed patent descriptions from PatentsView \n",
    "# !wget http://data.patentsview.org/detail-description-text/detail-desc-text-2016.tsv.zip # 2016 - 3.0 GB zipped\n",
    "# !wget http://data.patentsview.org/detail-description-text/detail-desc-text-2017.tsv.zip # 2017 - 2.8 GB zipped\n",
    "# !wget http://data.patentsview.org/detail-description-text/detail-desc-text-2018.tsv.zip # 2018 - 1.6 GB zipped\n",
    "# !wget http://data.patentsview.org/detail-description-text/detail-desc-text-2019.tsv.zip # 2019 - 0.7 GB zipped\n",
    "\n",
    "# !unzip files\n",
    "# unzip detail-desc-text-2016.tsv.zip\n",
    "# unzip detail-desc-text-2017.tsv.zip\n",
    "# unzip detail-desc-text-2018.tsv.zip\n",
    "# unzip detail-desc-text-2019.tsv.zip\n",
    "\n",
    "# def convert_bytes(num, suffix='B'):\n",
    "#     \"\"\" convert bytes int to int in aggregate units\"\"\"\n",
    "#     for unit in ['','K','M','G','T','P','E','Z']:\n",
    "#         if abs(num) < 1024.0:\n",
    "#             return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "#         num /= 1024.0\n",
    "#     return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "# path = \"data/\"\n",
    "# with os.scandir(path) as it:\n",
    "#     for entry in it:\n",
    "#         if not entry.name.startswith('.') and entry.is_file():\n",
    "#             print(entry.name)\n",
    "\n",
    "# # inspect unzipped file sizes\n",
    "\n",
    "# convert_bytes(os.path.getsize(\"data/detail-desc-text-2016.tsv\"))\n",
    "# convert_bytes(os.path.getsize(\"data/detail-desc-text-2017.tsv\"))\n",
    "# convert_bytes(os.path.getsize(\"data/detail-desc-text-2018.tsv\"))\n",
    "# convert_bytes(os.path.getsize(\"data/detail_desc_text_2019.tsv\"))\n",
    "\n",
    "#### Spark workflow\n",
    "\n",
    "# create SparkSession/SparkContext as entry point to Dataset/DataFrame API\n",
    "\n",
    "# spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "# sc = spark.sparkContext\n",
    "# sc\n",
    "\n",
    "# doc by doc read of large tsv files\n",
    "\n",
    "# with open \"data/detail-desc-text-2018.tsv\" as f_in:\n",
    "#     with open('data/2018_shard.tsv', 'w') as f_out:\n",
    "#         for line in f_in:\n",
    "#             if contains_keywords(line):\n",
    "#                 f_out.write(line)\n",
    "\n",
    "# from functools import reduce\n",
    "\n",
    "# df = reduce(lambda x,y: x.unionAll(y), \n",
    "#             [spark.read.format('csv')\n",
    "#                        .load(f, header=\"true\", inferSchema=\"true\") \n",
    "#              for f in files])\n",
    "# df.show()\n",
    "\n",
    "# files = [\"data/detail-desc-text-2016.tsv\", \"data/detail-desc-text-2017.tsv\", \n",
    "#          \"data/detail-desc-text-2018.tsv\", \"data/detail-desc-text-2019.tsv\"]\n",
    "\n",
    "# uncomment to use\n",
    "\n",
    "# df_2018 = (spark.read\n",
    "#                .format(\"csv\")\n",
    "#                .option(\"delimiter\", \"\\t\")\n",
    "#                .option('inferSchema', \"true\")\n",
    "#                .load(\"data/detail-desc-text-2018.tsv\")\n",
    "#                .write\n",
    "#                .format(\"parquet\")\n",
    "#                .save(\"df_2018.parquet\"))\n",
    "\n",
    "# df_2018 = (spark.read\n",
    "#                .format(\"csv\")\n",
    "#                .option(\"delimiter\", \"\\t\")\n",
    "#                .option('inferSchema', \"true\")\n",
    "#                .load(\"data/detail-desc-text-2018.tsv\"))\n",
    "\n",
    "# dfp_2018 = pd.read_csv(\"data/detail-desc-text-2018.tsv\", sep='\\t', header=None)\n",
    "\n",
    "# dfp_2018.columns = ['patent_number', 'desc_detail', 'len_detail']\n",
    "\n",
    "# dfp_2018_nl.head(3)\n",
    "\n",
    "# dfp_2018_nl = dfp_2018[dfp_2018['desc_detail'].str.contains('NLP')]\n",
    "\n",
    "# df_2018.printSchema()\n",
    "\n",
    "# schema = StructType([\n",
    "#             StructField(\"_c0\", IntegerType(), True),\n",
    "#             StructField(\"_c1\", StringType(), True),\n",
    "#             StructField(\"_c2\", IntegerType(), True)])\n",
    "\n",
    "# df_2018 = spark.read.load('data/df_2018.parquet')\n",
    "\n",
    "# # 160,249 rows in 2018 dataset\n",
    "# df_2018.count()\n",
    "\n",
    "# df_2018.rdd.getNumPartitions()\n",
    "\n",
    "# # partition / batching ?\n",
    "# df_2018.filter(df_2018._c1.contains(\"natural language\")).count()\n",
    "\n",
    "# query file directly with SQL\n",
    "\n",
    "# query = \"\"\"\n",
    "# SELECT * FROM parquet.`data/df_2018.parquet` WHERE _c1 LIKE 'natural language' LIMIT 100\n",
    "# \"\"\"\n",
    "\n",
    "# df_2018_nl = spark.sql(query)\n",
    "\n",
    "# df_2018_nl.head(3)\n",
    "\n",
    "# df_2018.columns\n",
    "\n",
    "# df_2018.explain()\n",
    "\n",
    "# df_2018.describe().show()\n",
    "\n",
    "# df_2018.dtypes\n",
    "\n",
    "# df_171819 = df_2017.union(df_2018).union(df_2019)\n",
    "\n",
    "# df_171819.count()\n",
    "\n",
    "# df_171819.head(3)\n",
    "\n",
    "# df_2018.head(3)\n",
    "\n",
    "# counts = df_2018.agg(F.countDistinct('_c0'))\n",
    "# counts\n",
    "\n",
    "# reviews_df.createOrReplaceTempView('reviews')\n",
    "\n",
    "# output = spark.sql(query)\n",
    "\n",
    "# show(output, n=1000)\n",
    "\n",
    "# results = spark.sql(\n",
    "#   \"SELECT * FROM people\")\n",
    "# names = results.map(lambda p: p.name)\n",
    "\n",
    "# df.rdd.isEmpty()\n",
    "\n",
    "# df = (spark.read\n",
    "#             .load(\"data/*.parquet\")\n",
    "#             .write\n",
    "#             .format(\"parquet\")\n",
    "#             .save(\"df.parquet\"))\n",
    "\n",
    "# df_2019 = (spark.read\n",
    "#                .format(\"csv\")\n",
    "#                .option(\"delimiter\", \"\\t\")\n",
    "#                .option('inferSchema', \"true\")\n",
    "#                .load(\"data/detail-desc-text-2018.tsv\")\n",
    "#                .write\n",
    "#                .format(\"parquet\")\n",
    "#                .save(\"df_2019.parquet\"))\n",
    "\n",
    "# df_2019.head(3)\n",
    "\n",
    "# type(df_2018)\n",
    "\n",
    "# df_2016.head(3)\n",
    "\n",
    "# df_2016 = (spark.read.format(\"csv\")\n",
    "#                .option(\"delimiter\", \"\\t\")\n",
    "#                .option(\"header\", \"true\")\n",
    "#                .option('inferSchema', \"true\")\n",
    "#                .load(\"data/detail-desc-text-2016.tsv\")\n",
    "#                .write\n",
    "#                .format(\"parquet\")\n",
    "#                .save(\"data/df_2016.parquet\"))\n",
    "\n",
    "# df_2016.head(3)\n",
    "\n",
    "# df = (spark.read.format(\"csv\")\n",
    "#            .option(\"delimiter\", \",\")\n",
    "#            .infer\n",
    "#            .load(\"data/df.csv\"))\n",
    "\n",
    "# df_2017 = (spark.read.format(\"csv\")\n",
    "#                .option(\"delimiter\", \"\\t\")\n",
    "#                .option(\"header\", \"true\")\n",
    "#                .option('inferSchema', \"true\")\n",
    "#                .load(\"data/detail-desc-text-2017.tsv\")\n",
    "#                .write\n",
    "#                .format(\"parquet\")\n",
    "#                .save(\"df_2017.parquet\"))\n",
    "\n",
    "# df_2018 = spark.read.parquet(\"data/df_2018.parquet\")\n",
    "\n",
    "# df_2018.head(2)\n",
    "\n",
    "# df_2018.persist()\n",
    "\n",
    "# df_2018.take(2)\n",
    "\n",
    "# df_2018.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bigram phrases model\n",
    "bigram_model = Phrases(filtered_data, min_count=1, threshold=1)\n",
    "\n",
    "# train trigram phrases model\n",
    "trigram_model = Phrases(bigram_model[filtered_data], threshold=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigrams\n",
    "def bigrams(docs):\n",
    "    \"\"\"create bigrams\"\"\"\n",
    "    return [bigram_model[doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize bigram and trigram models\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram_model)\n",
    "trigram_model = gensim.models.phrases.Phraser(trigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams(filtered_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams(docs):\n",
    "    \"\"\"create trigrams\"\"\"\n",
    "    return [trigram_model[bigram_model[doc]] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams(filtered_data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stem and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_docs(docs, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"lemmatize documents\"\"\"\n",
    "    lemmatized_docs = []\n",
    "    for doc in docs: \n",
    "        lemmatized_docs.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return lemmatized_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee)\n",
    "\n",
    "lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "# for doc in cleaned_data:\n",
    "#     for token in doc:\n",
    "#         token.lemma_\n",
    "\n",
    "# uncomment to use\n",
    "# download english model with \"python -m spacy download en\"\n",
    "\n",
    "# for token in doc:\n",
    "#     print(token, token.lemma, token.lemma_)\n",
    "\n",
    "# TODO (Lee) - lemmatize_docs(cleaned_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
