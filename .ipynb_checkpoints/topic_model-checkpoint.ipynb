{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniche - Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import mmcorpus\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import AuthorTopicModel\n",
    "from gensim.corpora import mmcorpus\n",
    "from gensim.test.utils import common_dictionary, datapath, temporary_file\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, punkt, RegexpTokenizer, wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from topic_model import tokenize_docs\n",
    "\n",
    "import os, re\n",
    "from smart_open import smart_open\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download stop words from nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data from PatentsView API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# patents endpoint\n",
    "endpoint_url = 'http://www.patentsview.org/api/patents/query'\n",
    "\n",
    "# build list of possible fields that endpoint request will return\n",
    "df = pd.read_excel(\"data/patents_view_patents_fields.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "pat_fields = df.api_field_name.values.tolist()\n",
    "\n",
    "# build query\n",
    "query={\"_or\":[{\"_text_phrase\":{\"patent_title\":\"natural language\"}},{\"_text_phrase\":{\"patent_abstract\":\"natural language\"}}]}\n",
    "fields=pat_fields\n",
    "options={\"per_page\":2500}\n",
    "sort=[{\"patent_date\":\"desc\"}]\n",
    "\n",
    "params={'q': json.dumps(query),\n",
    "        'f': json.dumps(fields),\n",
    "        'o': json.dumps(options),\n",
    "        's': json.dumps(sort)}\n",
    "\n",
    "# request and results\n",
    "resp = requests.get(endpoint_url, params=params)\n",
    "results = resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code: 200 ; reason: OK\n",
      "total_patent_count: 2482 ; patents_per_page: 2482\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCs</th>\n",
       "      <th>application_citations</th>\n",
       "      <th>applications</th>\n",
       "      <th>assignees</th>\n",
       "      <th>cited_patents</th>\n",
       "      <th>citedby_patents</th>\n",
       "      <th>cpcs</th>\n",
       "      <th>detail_desc_length</th>\n",
       "      <th>examiners</th>\n",
       "      <th>foreign_priority</th>\n",
       "      <th>gov_interests</th>\n",
       "      <th>inventors</th>\n",
       "      <th>lawyers</th>\n",
       "      <th>nbers</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_average_processing_time</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_firstnamed_assignee_city</th>\n",
       "      <th>patent_firstnamed_assignee_country</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_firstnamed_assignee_latitude</th>\n",
       "      <th>patent_firstnamed_assignee_location_id</th>\n",
       "      <th>patent_firstnamed_assignee_longitude</th>\n",
       "      <th>patent_firstnamed_assignee_state</th>\n",
       "      <th>patent_firstnamed_inventor_city</th>\n",
       "      <th>patent_firstnamed_inventor_country</th>\n",
       "      <th>patent_firstnamed_inventor_id</th>\n",
       "      <th>patent_firstnamed_inventor_latitude</th>\n",
       "      <th>patent_firstnamed_inventor_location_id</th>\n",
       "      <th>patent_firstnamed_inventor_longitude</th>\n",
       "      <th>patent_firstnamed_inventor_state</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_num_cited_by_us_patents</th>\n",
       "      <th>patent_num_claims</th>\n",
       "      <th>patent_num_combined_citations</th>\n",
       "      <th>patent_num_foreign_citations</th>\n",
       "      <th>patent_num_us_application_citations</th>\n",
       "      <th>patent_num_us_patent_citations</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_processing_time</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>pct_data</th>\n",
       "      <th>rawinventors</th>\n",
       "      <th>uspcs</th>\n",
       "      <th>wipos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020077823', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2013-07-26...</td>\n",
       "      <td>[{'assignee_city': 'Burlington', 'assignee_cou...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by examiner'...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>11570</td>\n",
       "      <td>[{'examiner_first_name': 'Michael N', 'examine...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Newton', 'inventor_country...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>US</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>42.5047</td>\n",
       "      <td>42.5047|-71.1961</td>\n",
       "      <td>-71.1961</td>\n",
       "      <td>MA</td>\n",
       "      <td>Newton</td>\n",
       "      <td>US</td>\n",
       "      <td>7788103-1</td>\n",
       "      <td>42.3369</td>\n",
       "      <td>42.3369|-71.2097</td>\n",
       "      <td>-71.2097</td>\n",
       "      <td>MA</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>10229106</td>\n",
       "      <td>2055</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Jeffrey N.', 'raw...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020138265', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2017-09-11...</td>\n",
       "      <td>[{'assignee_city': 'Mountain View', 'assignee_...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>28118</td>\n",
       "      <td>[{'examiner_first_name': 'Shreyans A', 'examin...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Adliswil', 'inventor_count...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>US</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>37.3861</td>\n",
       "      <td>37.3861|-122.0828</td>\n",
       "      <td>-122.083</td>\n",
       "      <td>CA</td>\n",
       "      <td>Adliswil</td>\n",
       "      <td>CH</td>\n",
       "      <td>8352247-1</td>\n",
       "      <td>47.3119</td>\n",
       "      <td>47.3119|8.5287</td>\n",
       "      <td>8.5287</td>\n",
       "      <td>None</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10229109</td>\n",
       "      <td>547</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Evgeny A.', 'rawi...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2001/20010029455', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2016-09-28...</td>\n",
       "      <td>[{'assignee_city': 'Seattle', 'assignee_countr...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>119654</td>\n",
       "      <td>[{'examiner_first_name': 'Jialong', 'examiner_...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Seattle', 'inventor_countr...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>9177341-1</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>10229113</td>\n",
       "      <td>895</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Thibault Pierre',...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                IPCs  \\\n",
       "0  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "1  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "2  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "\n",
       "                               application_citations  \\\n",
       "0  [{'appcit_app_number': '2002/20020077823', 'ap...   \n",
       "1  [{'appcit_app_number': '2002/20020138265', 'ap...   \n",
       "2  [{'appcit_app_number': '2001/20010029455', 'ap...   \n",
       "\n",
       "                                        applications  \\\n",
       "0  [{'app_country': 'US', 'app_date': '2013-07-26...   \n",
       "1  [{'app_country': 'US', 'app_date': '2017-09-11...   \n",
       "2  [{'app_country': 'US', 'app_date': '2016-09-28...   \n",
       "\n",
       "                                           assignees  \\\n",
       "0  [{'assignee_city': 'Burlington', 'assignee_cou...   \n",
       "1  [{'assignee_city': 'Mountain View', 'assignee_...   \n",
       "2  [{'assignee_city': 'Seattle', 'assignee_countr...   \n",
       "\n",
       "                                       cited_patents  \\\n",
       "0  [{'cited_patent_category': 'cited by examiner'...   \n",
       "1  [{'cited_patent_category': 'cited by applicant...   \n",
       "2  [{'cited_patent_category': 'cited by applicant...   \n",
       "\n",
       "                                     citedby_patents  \\\n",
       "0  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "1  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "2  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "\n",
       "                                                cpcs detail_desc_length  \\\n",
       "0  [{'cpc_category': None, 'cpc_first_seen_date':...              11570   \n",
       "1  [{'cpc_category': None, 'cpc_first_seen_date':...              28118   \n",
       "2  [{'cpc_category': None, 'cpc_first_seen_date':...             119654   \n",
       "\n",
       "                                           examiners  \\\n",
       "0  [{'examiner_first_name': 'Michael N', 'examine...   \n",
       "1  [{'examiner_first_name': 'Shreyans A', 'examin...   \n",
       "2  [{'examiner_first_name': 'Jialong', 'examiner_...   \n",
       "\n",
       "                                    foreign_priority  \\\n",
       "0  [{'forprior_country': None, 'forprior_date': N...   \n",
       "1  [{'forprior_country': None, 'forprior_date': N...   \n",
       "2  [{'forprior_country': None, 'forprior_date': N...   \n",
       "\n",
       "                                       gov_interests  \\\n",
       "0  [{'govint_contract_award_number': None, 'govin...   \n",
       "1  [{'govint_contract_award_number': None, 'govin...   \n",
       "2  [{'govint_contract_award_number': None, 'govin...   \n",
       "\n",
       "                                           inventors  \\\n",
       "0  [{'inventor_city': 'Newton', 'inventor_country...   \n",
       "1  [{'inventor_city': 'Adliswil', 'inventor_count...   \n",
       "2  [{'inventor_city': 'Seattle', 'inventor_countr...   \n",
       "\n",
       "                                             lawyers  \\\n",
       "0  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "1  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "2  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "\n",
       "                                               nbers  \\\n",
       "0  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "1  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "2  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_average_processing_time patent_date patent_firstnamed_assignee_city  \\\n",
       "0                           None  2019-03-12                      Burlington   \n",
       "1                           None  2019-03-12                   Mountain View   \n",
       "2                           None  2019-03-12                         Seattle   \n",
       "\n",
       "  patent_firstnamed_assignee_country patent_firstnamed_assignee_id  \\\n",
       "0                                 US      org_ID497r4tFbCIaMBjGAST   \n",
       "1                                 US      org_p6ofWD2xFNSnyYkj6wpA   \n",
       "2                                 US      org_Vbc6obpnxWM42d0HjlXY   \n",
       "\n",
       "  patent_firstnamed_assignee_latitude patent_firstnamed_assignee_location_id  \\\n",
       "0                             42.5047                       42.5047|-71.1961   \n",
       "1                             37.3861                      37.3861|-122.0828   \n",
       "2                             47.6064                      47.6064|-122.3308   \n",
       "\n",
       "  patent_firstnamed_assignee_longitude patent_firstnamed_assignee_state  \\\n",
       "0                             -71.1961                               MA   \n",
       "1                             -122.083                               CA   \n",
       "2                             -122.331                               WA   \n",
       "\n",
       "  patent_firstnamed_inventor_city patent_firstnamed_inventor_country  \\\n",
       "0                          Newton                                 US   \n",
       "1                        Adliswil                                 CH   \n",
       "2                         Seattle                                 US   \n",
       "\n",
       "  patent_firstnamed_inventor_id patent_firstnamed_inventor_latitude  \\\n",
       "0                     7788103-1                             42.3369   \n",
       "1                     8352247-1                             47.3119   \n",
       "2                     9177341-1                             47.6064   \n",
       "\n",
       "  patent_firstnamed_inventor_location_id patent_firstnamed_inventor_longitude  \\\n",
       "0                       42.3369|-71.2097                             -71.2097   \n",
       "1                         47.3119|8.5287                               8.5287   \n",
       "2                      47.6064|-122.3308                             -122.331   \n",
       "\n",
       "  patent_firstnamed_inventor_state patent_kind patent_num_cited_by_us_patents  \\\n",
       "0                               MA          B2                              0   \n",
       "1                             None          B1                              0   \n",
       "2                               WA          B1                              0   \n",
       "\n",
       "  patent_num_claims patent_num_combined_citations  \\\n",
       "0                19                            31   \n",
       "1                20                            15   \n",
       "2                20                            74   \n",
       "\n",
       "  patent_num_foreign_citations patent_num_us_application_citations  \\\n",
       "0                            0                                  26   \n",
       "1                            0                                   7   \n",
       "2                            0                                  48   \n",
       "\n",
       "  patent_num_us_patent_citations patent_number patent_processing_time  \\\n",
       "0                              5      10229106                   2055   \n",
       "1                              8      10229109                    547   \n",
       "2                             26      10229113                    895   \n",
       "\n",
       "                                        patent_title patent_type patent_year  \\\n",
       "0  Initializing a workspace for building a natura...     utility        2019   \n",
       "1               Allowing spelling of arbitrary words     utility        2019   \n",
       "2  Leveraging content dimensions during the trans...     utility        2019   \n",
       "\n",
       "                                            pct_data  \\\n",
       "0  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "1  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "2  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "\n",
       "                                        rawinventors  \\\n",
       "0  [{'rawinventor_first_name': 'Jeffrey N.', 'raw...   \n",
       "1  [{'rawinventor_first_name': 'Evgeny A.', 'rawi...   \n",
       "2  [{'rawinventor_first_name': 'Thibault Pierre',...   \n",
       "\n",
       "                                               uspcs  \\\n",
       "0  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "1  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "2  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "\n",
       "                                               wipos  \n",
       "0  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "1  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "2  [{'wipo_field_id': None, 'wipo_field_title': N...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract metadata from response\n",
    "print(\"status code:\", resp.status_code,';', \"reason:\", resp.reason)\n",
    "total_patent_count = results[\"total_patent_count\"]\n",
    "patents_per_page = results['count']\n",
    "print(\"total_patent_count:\",total_patent_count,';', \"patents_per_page:\", patents_per_page)\n",
    "\n",
    "# extract data from response\n",
    "data = results['patents']\n",
    "# data[0]\n",
    "raw_df = pd.DataFrame(data)\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset dataframe - comment/uncomment to include fields\n",
    "df = raw_df[['patent_number', \n",
    "         'patent_date', \n",
    "         'patent_title',\n",
    "         'patent_abstract', \n",
    "         'patent_firstnamed_assignee_id',\n",
    "         'patent_firstnamed_assignee_location_id',\n",
    "         'patent_firstnamed_assignee_latitude',\n",
    "         'patent_firstnamed_assignee_longitude',\n",
    "         'patent_firstnamed_assignee_city',\n",
    "         'patent_firstnamed_assignee_state',\n",
    "         'patent_firstnamed_assignee_country', \n",
    "         'patent_firstnamed_inventor_id',\n",
    "         'patent_firstnamed_inventor_location_id',\n",
    "         'patent_firstnamed_inventor_latitude',\n",
    "         'patent_firstnamed_inventor_longitude',\n",
    "         'patent_firstnamed_inventor_city',\n",
    "         'patent_firstnamed_inventor_state',\n",
    "         'patent_firstnamed_inventor_country',\n",
    "         'patent_year', \n",
    "         'patent_type', \n",
    "         'patent_kind',\n",
    "#          'patent_processing_time', \n",
    "#          'patent_num_us_application_citations', \n",
    "#          'patent_num_us_patent_citations', \n",
    "#          'patent_num_foreign_citations', \n",
    "#          'patent_num_combined_citations', \n",
    "#          'patent_num_claims', \n",
    "#          'patent_num_cited_by_us_patents',\n",
    "#          'detail_desc_length'\n",
    "            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>4502128</td>\n",
       "      <td>Translation between natural languages An input...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patent_number                              patent_title_abstract  \\\n",
       "2479       4502128  Translation between natural languages An input...   \n",
       "\n",
       "     patent_firstnamed_assignee_id  \n",
       "2479      org_70D1lR89kQnFiCFdJ6s5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column that combines the patent title and the patent abstract columns into a single string\n",
    "df['patent_title_abstract'] = df.patent_title + ' ' + df.patent_abstract\n",
    "df.patent_title_abstract.head(3)\n",
    "\n",
    "# 561 different assignees\n",
    "len(df.patent_firstnamed_assignee_id.unique())\n",
    "\n",
    "df.patent_firstnamed_assignee_id.value_counts()[:10]\n",
    "\n",
    "# subset dataframe by filtering for inclusion the asignees with > 20 NLP patents\n",
    "\n",
    "# 561 different assignees\n",
    "len(df.patent_firstnamed_assignee_id.unique())\n",
    "df.patent_firstnamed_assignee_id.value_counts()[:10]\n",
    "\n",
    "# list of assignees with > 20 patents in df dataset\n",
    "assignees_list = ['org_q9Bn28RHhpYrQjKvraAH', 'org_JZguWDMfFOBX2wBI9pnD', 'org_ID497r4tFbCIaMBjGAST', \n",
    "                  'org_rDyHZBYWMcBEtnkHt05L', 'org_p6ofWD2xFNSnyYkj6wpA', 'org_EilEWQcC6UiqHcSGx9mb',\n",
    "                  'org_ccMMcUijAIsKIxUqMTyP', 'org_Vbc6obpnxWM42d0HjlXY', 'org_9D8x1qL3IRASp6GG7Glu',\n",
    "                  'org_2wAdIFKssfcLHpZq0u4H', 'org_iwO2oOJ6VIBd9fAuP7G6', 'org_70D1lR89kQnFiCFdJ6s5',\n",
    "                  'org_vojVnDkT9CamDETqbqJC']\n",
    "\n",
    "df_20pats = df[df['patent_firstnamed_assignee_id'].isin(assignees_list) ]\n",
    "df_20pats.sort_values(by=['patent_date'], inplace=True)\n",
    "\n",
    "df_20pats[['patent_number','patent_title_abstract', 'patent_firstnamed_assignee_id']].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition data sorted by patent date into train and test sets, at 80/20 split\n",
    "train_20pats = df_20pats[:894]\n",
    "len(train_20pats)\n",
    "\n",
    "test_20pats = df_20pats[894:]\n",
    "len(test_20pats)\n",
    "\n",
    "# convert text column to list\n",
    "data = train_20pats.patent_title_abstract.values.tolist()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize documents\n",
    "\n",
    "def tokenize_docs(docs):\n",
    "    tokenized_docs = []\n",
    "    for doc in docs:\n",
    "        tokenized_docs.append(word_tokenize(doc))\n",
    "    return tokenized_docs\n",
    "\n",
    "tokenized_docs = tokenize_docs(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean punctuation\n",
    "def clean_docs(tokenized_docs):\n",
    "    clean_docs = []\n",
    "    for doc in tokenized_docs:\n",
    "       clean_docs.append([word for word in doc if word.isalpha()])  \n",
    "    return clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_docs(tokenized_docs)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "def lower_words(docs):\n",
    "    lowered_words = []\n",
    "    for doc in docs:\n",
    "        lowered_words.append([word.lower() for word in doc])\n",
    "    return lowered_words\n",
    "\n",
    "lower_words(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(clean_docs):\n",
    "    filtered_docs = []\n",
    "    for doc in clean_docs:\n",
    "       filtered_docs.append([word for word in doc if word not in stop_words])\n",
    "    return filtered_docs\n",
    "\n",
    "# remove stopwords\n",
    "cleaned_data = remove_stopwords(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bigram phrases model\n",
    "bigram_model = Phrases(data, min_count=1, threshold=1)\n",
    "\n",
    "# train trigram phrases model\n",
    "trigram_model = Phrases(bigram_model[data], threshold=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigrams\n",
    "def bigrams(docs):\n",
    "    \"\"\"create bigrams\"\"\"\n",
    "    return [bigram_model[doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize bigram and trigram models\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram_model)\n",
    "trigram_model = gensim.models.phrases.Phraser(trigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams(docs):\n",
    "    \"\"\"create trigrams\"\"\"\n",
    "    return [trigram_model[bigram_model[doc]] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stem and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_docs(docs, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"lemmatize documents\"\"\"\n",
    "    lemmatized_docs = []\n",
    "    for doc in docs: \n",
    "        lemmatized_docs.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return lemmatized_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee)\n",
    "# for doc in cleaned_data:\n",
    "#     for token in doc:\n",
    "#         token.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to use\n",
    "# download english model with \"python -m spacy download en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token, token.lemma, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - lemmatize_docs(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create corpus and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # build dictionary\n",
    "id_word = corpora.Dictionary(cleaned_data)\n",
    "\n",
    "# build corpus\n",
    "texts = cleaned_data\n",
    "\n",
    "# apply term document frequency\n",
    "# converts documents in corpus to bag-of-words format, a list of (token_id, token_count) tuples\n",
    "corpus = [id_word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Lee) - deprecation warnings\n",
    "# construct LDA model\n",
    "# Build LDA model\n",
    "model_lda = LdaModel(corpus=corpus,\n",
    "                     id2word=id2word,\n",
    "                     num_topics=25, \n",
    "                     random_state=100,\n",
    "                     update_every=1,\n",
    "                     chunksize=100,\n",
    "                     passes=10,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print keywords in 10 topics\n",
    "pprint(model_lda.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print keywords in 10 topics\n",
    "pprint(model_lda.print_topic(0))\n",
    "# the most import keywords, and the respective weight, that form topic 0 are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer topic from keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate perplexity metrics\n",
    "perplexity = model_lda.log_perplexity(corpus)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coherence metric\n",
    "coherence = CoherenceModel(model=model_lda, texts=data, dictionary=id_word, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_1 = coherence.get_coherence()\n",
    "coherence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces coherence_per_topic\n",
    "coherence_1 = coherence.get_coherence_per_topic()\n",
    "coherence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore topics\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_topics_1 = pyLDAvis.gensim.prepare(model_lda, corpus, id_word)\n",
    "viz_topics_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Mallet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download Mallet topic model\n",
    "# !wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "# update this path\n",
    "path_mallet = 'data/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = gensim.models.wrappers.LdaMallet(path_mallet, corpus=corpus, num_topics=25, id2word=id_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics\n",
    "pprint(model_2.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coherence metric\n",
    "coherence_model_2 = CoherenceModel(model=model_2, texts=data, dictionary=id_word, coherence='c_v')\n",
    "coherence_model_2 = coherence_model_2.get_coherence()\n",
    "coherence_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "#     \"\"\"\n",
    "#     Compute c_v coherence for various number of topics\n",
    "\n",
    "#     Parameters:\n",
    "#     ----------\n",
    "#     dictionary : Gensim dictionary\n",
    "#     corpus : Gensim corpus\n",
    "#     texts : List of input texts\n",
    "#     limit : Max num of topics\n",
    "\n",
    "#     Returns:\n",
    "#     -------\n",
    "#     model_list : List of LDA topic models\n",
    "#     coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "#     \"\"\"\n",
    "#     coherence_values = []\n",
    "#     model_list = []\n",
    "#     for num_topics in range(start, limit, step):\n",
    "#         model = gensim.models.wrappers.LdaMallet(path_mallet, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "#         model_list.append(model)\n",
    "#         coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "#         coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "#     return model_list, coherence_values\n",
    "\n",
    "# model_list, coherence_values = compute_coherence_values(dictionary=id_word, corpus=corpus, texts=data, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Author topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct author-topic model\n",
    "model_at = AuthorTopicModel(corpus=corpus,\n",
    "                         author2doc=author2doc,\n",
    "                         id2word=id_word, \n",
    "                         num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim example\n",
    "# mmcorpus.IndexedCorpus\n",
    "# from gensim.models import AuthorTopicModel\n",
    "# from gensim.corpora import mmcorpus\n",
    "# from gensim.test.utils import common_dictionary, datapath, temporary_file\n",
    "\n",
    "# gensim author2doc format example:\n",
    "author2doc = {\n",
    "     'john': [0, 1, 2, 3, 4, 5, 6],\n",
    "     'jane': [2, 3, 4, 5, 6, 7, 8],\n",
    "     'jack': [0, 2, 4, 6, 8]\n",
    " }\n",
    "author2doc\n",
    "\n",
    "# corpus = mmcorpus.MmCorpus(datapath('testcorpus.mm'))\n",
    "# corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct inventor-to-doc df from extract nested inventors column from raw df\n",
    "df_inventors = json_normalize(results['patents'], record_path=['inventors'], meta=['patent_number'])\n",
    "df_inventors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct vectors for authors\n",
    "author_vecs = [model.get_author_topics(author) for author in model.id2author.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Construct a mapping from authors to document IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [data_dir + 'idx/a' + yr + '.txt' for yr in yrs]  # Using the years defined in previous cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
